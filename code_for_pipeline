import os
import glob
import joblib
import torch
import pandas as pd
import numpy as np
from sklearn.preprocessing import OrdinalEncoder, StandardScaler
from sentence_transformers import SentenceTransformer

# --- DEVICE SETUP ---
device = 'cuda' if torch.cuda.is_available() else 'cpu'
encoder = SentenceTransformer('pritamdeka/BioBERT-mnli-snli-scinli-scitail-mednli-stsb', device=device)
ordinal = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)
scaler = StandardScaler()

# --- CONFIG ---model_artifects
input_path = './data/target_map_cleaned_non_null_target'
embedding_cache_dir = './data/validation_step/model_artifects/bert_embedding'
os.makedirs(embedding_cache_dir, exist_ok=True)
required_cols = [
    'CMPNT_MATL_DESC', 'CMPNT_MATL_DESC_LEN', 'UNIT_GROUP',
    'CMPNT_MATL_TYPE_CATEGORY', 'Final Category'
]
all_files = glob.glob(os.path.join(input_path, '*.parquet'))

# --- LOAD DATA ---
df_list = []
for file in all_files:
    df = pd.read_parquet(file, columns=required_cols)
    df = df[df['Final Category'].notna() & df['CMPNT_MATL_DESC'].notna()].copy()
    df['Final Category'] = df['Final Category'].replace({'FNW or CHM': 'FNW_CHM'})
    df.drop_duplicates(inplace=True)
    df_list.append(df)

df_all = pd.concat(df_list, ignore_index=True)
print(f"‚úÖ Loaded {len(df_all)} records for BERT feature generation")

# --- FIT ENCODERS ---
ordinal.fit(df_all[['UNIT_GROUP', 'CMPNT_MATL_TYPE_CATEGORY']])
scaler.fit(df_all[['CMPNT_MATL_DESC_LEN']])
joblib.dump(ordinal, './data/validation_step/model_artifects/ordinal_encoder.pkl')
joblib.dump(scaler, './data/validation_step/model_artifects/scaler.pkl')
print("‚úÖ OrdinalEncoder and Scaler saved")

# --- GENERATE BERT EMBEDDINGS ---
desc_texts = df_all['CMPNT_MATL_DESC'].astype(str).tolist()
bert_cache_file = os.path.join(embedding_cache_dir, "bert_emb_full.npy")

if os.path.exists(bert_cache_file):
    print(f"üîÅ Loading cached embeddings from: {bert_cache_file}")
    desc_emb = np.load(bert_cache_file)
else:
    desc_emb = encoder.encode(
        desc_texts,
        batch_size=256,
        show_progress_bar=True,
        convert_to_numpy=True
    )
    np.save(bert_cache_file, desc_emb)
    print("‚úÖ BERT embeddings generated and saved")

# --- CONCATENATE FINAL FEATURES ---
length_scaled = scaler.transform(df_all[['CMPNT_MATL_DESC_LEN']])
cat_encoded = ordinal.transform(df_all[['UNIT_GROUP', 'CMPNT_MATL_TYPE_CATEGORY']])
X_full = np.hstack([desc_emb, length_scaled, cat_encoded])
y_full = df_all['Final Category'].values

np.save('./data/validation_step/model_artifects/X_full.npy', X_full)
np.save('./data/validation_step/model_artifects/y_full.npy', y_full)
print("‚úÖ Final BERT+Meta feature matrix saved: X_full.npy, y_full.npy")
