# azureml_pipeline/steps/1_download_data.py
import os
import argparse
from azureml.core import Workspace, Dataset

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--output_path', type=str, required=True)
    args = parser.parse_args()

    ws = Workspace.from_config()
    dataset = Dataset.get_by_name(ws, name='harmonized_bom_data_asset')

    os.makedirs(args.output_path, exist_ok=True)
    dataset.download(target_path=args.output_path, overwrite=True)
    print(f"✅ Dataset downloaded to {args.output_path}")

if __name__ == '__main__':
    main()


# azureml_pipeline/steps/2_target_map_join.py
import os
import glob
import argparse
import polars as pl

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--input_path', type=str, required=True)
    parser.add_argument('--output_path', type=str, required=True)
    args = parser.parse_args()

    os.makedirs(args.output_path, exist_ok=True)

    target_map_df = pl.read_csv('./data/target_map.csv', columns=['CMPNT_CAT_CD_DESC', 'Final Category']).unique()
    columns_to_read = [
        'MATL_SHRT_DESC', 'CMPNT_MATL_DESC', 'CMPNT_MATL_TYPE_CD',
        'CMPNT_CAT_CD_DESC', 'CMPNT_UOM_CD']

    all_files = glob.glob(os.path.join(args.input_path, '*.parquet'))
    for idx, file in enumerate(all_files):
        df = pl.read_parquet(file).select(columns_to_read).unique()
        joined = df.join(target_map_df, on='CMPNT_CAT_CD_DESC', how='left')
        joined.write_parquet(os.path.join(args.output_path, f'mapped_file{idx}.parquet'), compression='snappy')
        print(f"✅ Joined: {os.path.basename(file)}")

if __name__ == '__main__':
    main()


# azureml_pipeline/steps/3_text_cleaning.py
import os
import re
import glob
import argparse
import pandas as pd

patterns = {
    'non_alphanumeric': re.compile(r'[^A-Za-z0-9&% ]+'),
    'percent_space': re.compile(r"\s*%\s*"),
    'canada_variants': re.compile(r'(canada|can|(ca\d+)$|ca)'),
    'remove_canada': re.compile(r'canada\s*(\d{2,})|(canada\d+)|canada|can\s*(\d{2,})|(can\d+)|can|(ca\d+)|ca\s(\d{2,})|ca$|(ca\s)'),
    'units': re.compile(r"(\D)(\d+)(\s*)(ml|l|gr|gm|g|ct)"),
    'spf_space': re.compile(r"(\s)(spf)\s*([\d+])"),
    'units_no_space': re.compile(r'([\d+])\s*(?:ml|l|gr|gm|g|ct)(?: |$)'),
    'spf_number': re.compile(r"(\D)(spf\d+)")
}

def clean_series(series):
    return (series.str.lower()
        .str.replace(patterns['non_alphanumeric'], '', regex=True)
        .str.replace(patterns['percent_space'], '% ', regex=True)
        .str.replace(patterns['canada_variants'], r' \1', regex=True)
        .str.replace(patterns['remove_canada'], '', regex=True)
        .str.replace(patterns['units'], r'\1 \2\3\4 ', regex=True)
        .str.replace(patterns['spf_space'], r'\1\2\3', regex=True)
        .str.replace(patterns['units_no_space'], lambda z: z.group().replace(" ", ""), regex=True)
        .str.replace(patterns['spf_number'], r'\1 \2 ', regex=True)
    )

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--input_path', type=str, required=True)
    parser.add_argument('--output_path', type=str, required=True)
    args = parser.parse_args()

    os.makedirs(args.output_path, exist_ok=True)
    all_files = glob.glob(os.path.join(args.input_path, '*.parquet'))

    for file in all_files:
        df = pd.read_parquet(file)
        df = df[df['Final Category'].notna()]
        if df.empty:
            continue
        df['MATL_SHRT_DESC'] = clean_series(df['MATL_SHRT_DESC'].fillna(''))
        df['CMPNT_MATL_DESC'] = clean_series(df['CMPNT_MATL_DESC'].fillna(''))
        df['MATL_SHRT_DESC_AND_CMPNT_MATL_DESC'] = (df['MATL_SHRT_DESC'] + ' ' + df['CMPNT_MATL_DESC']).str.strip()

        out_file = os.path.join(args.output_path, os.path.basename(file))
        df.to_parquet(out_file, index=False)
        print(f"✅ Cleaned: {os.path.basename(file)}")

if __name__ == '__main__':
    main()
