# Single-Stage Classification Pipeline using BioBERT Embeddings (Optimized)
import os
import glob
import joblib
import torch
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OrdinalEncoder, StandardScaler
from sklearn.metrics import classification_report, confusion_matrix, f1_score
from lightgbm import LGBMClassifier
from sentence_transformers import SentenceTransformer

# --- ENCODERS ---
device = 'cuda' if torch.cuda.is_available() else 'cpu'
# Confirm GPU status
print(f"âœ… Using device: {device}")
if torch.cuda.is_available():
    print(f"ðŸ§  GPU Detected: {torch.cuda.get_device_name(0)}")
    print(f"ðŸ§® GPU Memory Allocated: {torch.cuda.memory_allocated() / 1e6:.2f} MB")
    print(f"ðŸ§® GPU Memory Cached: {torch.cuda.memory_reserved() / 1e6:.2f} MB")
device = 'cuda' if torch.cuda.is_available() else 'cpu'
encoder = SentenceTransformer('pritamdeka/BioBERT-mnli-snli-scinli-scitail-mednli-stsb', device=device)
ordinal = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)
scaler = StandardScaler()

# --- CONFIGURATION ---
input_path = './data/target_map_cleaned_non_null_target'
all_files = glob.glob(os.path.join(input_path, '*.parquet'))
required_cols = [
    'CMPNT_MATL_DESC', 'CMPNT_MATL_DESC_LEN', 'UNIT_GROUP',
    'CMPNT_MATL_TYPE_CATEGORY', 'Final Category'
]
os.makedirs("./saved_model", exist_ok=True)

# --- LOAD DATA ---
sample_list = []
for file in all_files:
    df = pd.read_parquet(file, columns=required_cols)
    df = df[df['Final Category'].notna() & df['CMPNT_MATL_DESC'].notna()].copy()
    df['Final Category'] = df['Final Category'].replace({'FNW or CHM': 'FNW_CHM'})
    df.drop_duplicates(inplace=True)

    # Take 20% stratified sample from each Final Category per file
    sampled = df.groupby('Final Category', group_keys=False).apply(lambda x: x.sample(frac=0.2, random_state=42))
    sample_list.append(sampled)

df_all = pd.concat(sample_list, ignore_index=True)

# Print sample distribution summary
print("
ðŸ“Š Sample distribution by Final Category:")
print(df_all['Final Category'].value_counts())

# --- FIT SCALERS ---
ordinal.fit(df_all[['UNIT_GROUP', 'CMPNT_MATL_TYPE_CATEGORY']])
scaler.fit(df_all[['CMPNT_MATL_DESC_LEN']])

def transform(df):
    desc_emb = encoder.encode(
        df['CMPNT_MATL_DESC'].astype(str).tolist(),
        batch_size=128,
        show_progress_bar=True,
        convert_to_numpy=True
    )
    length_scaled = scaler.transform(df[['CMPNT_MATL_DESC_LEN']])
    cat_encoded = ordinal.transform(df[['UNIT_GROUP', 'CMPNT_MATL_TYPE_CATEGORY']])
    return np.hstack([desc_emb, length_scaled, cat_encoded])

# --- SPLIT ---
train_df, temp_df = train_test_split(df_all, test_size=0.2, stratify=df_all['Final Category'], random_state=42)
val_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df['Final Category'], random_state=42)

# --- TRAIN FINAL CATEGORY MODEL ---
X_train = transform(train_df)
y_train = train_df['Final Category']
X_val = transform(val_df)
y_val = val_df['Final Category']

final_model = LGBMClassifier(class_weight='balanced', random_state=42)
final_model.fit(X_train, y_train, eval_set=[(X_val, y_val)], early_stopping_rounds=5, verbose=10)
joblib.dump(final_model, './saved_model/final_biobert_model.joblib')

# --- INFERENCE ---
X_test = transform(test_df)
predicted = final_model.predict(X_test)
test_df['Predicted'] = predicted
test_df.to_csv('./saved_model/final_biobert_predictions.csv', index=False)

# --- EVALUATION ---
print("\nClassification Report:")
report = classification_report(test_df['Final Category'], test_df['Predicted'])
print(report)

print("\nConfusion Matrix:")
print(confusion_matrix(test_df['Final Category'], test_df['Predicted']))

f1 = f1_score(test_df['Final Category'], test_df['Predicted'], average='weighted')
print(f"\nF1 Score (weighted): {f1:.4f}")

# --- SAVE REPORT ---
with open('./saved_model/classification_report.txt', 'w') as f:
    f.write(report)
    f.write(f"\nF1 Score (weighted): {f1:.4f}\n")
