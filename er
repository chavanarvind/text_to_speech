#bert without layer
# Single-Stage Classification Pipeline using BioBERT Embeddings
import os
import glob
import joblib
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OrdinalEncoder, StandardScaler
from sklearn.metrics import classification_report, confusion_matrix, f1_score
from lightgbm import LGBMClassifier
from sentence_transformers import SentenceTransformer

# --- ENCODERS ---
encoder = SentenceTransformer('pritamdeka/BioBERT-mnli-snli-scinli-scitail-mednli-stsb')
ordinal = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)
scaler = StandardScaler()

# --- CONFIGURATION ---
input_path = './data/target_map_cleaned_non_null_target'
all_files = glob.glob(os.path.join(input_path, '*.parquet'))
required_cols = [
    'CMPNT_MATL_DESC', 'CMPNT_MATL_DESC_LEN', 'UNIT_GROUP',
    'CMPNT_MATL_TYPE_CATEGORY', 'Final Category'
]
os.makedirs("./saved_model", exist_ok=True)

# --- LOAD DATA ---
sample_list = []
for file in all_files:
    df = pd.read_parquet(file, columns=required_cols)
    df = df[df['Final Category'].notna() & df['CMPNT_MATL_DESC'].notna()].copy()
    df['Final Category'] = df['Final Category'].replace({'FNW or CHM': 'FNW_CHM'})
    df.drop_duplicates(inplace=True)
    sample_list.append(df)

df_all = pd.concat(sample_list, ignore_index=True)



ordinal.fit(df_all[['UNIT_GROUP', 'CMPNT_MATL_TYPE_CATEGORY']])
scaler.fit(df_all[['CMPNT_MATL_DESC_LEN']])

def transform(df):
    desc_emb = encoder.encode(df['CMPNT_MATL_DESC'].astype(str).tolist(), show_progress_bar=True)
    length_scaled = scaler.transform(df[['CMPNT_MATL_DESC_LEN']])
    cat_encoded = ordinal.transform(df[['UNIT_GROUP', 'CMPNT_MATL_TYPE_CATEGORY']])
    return np.hstack([desc_emb, length_scaled, cat_encoded])

# --- SPLIT ---
train_df, test_df = train_test_split(df_all, test_size=0.2, stratify=df_all['Final Category'], random_state=42)
val_df, test_df = train_test_split(test_df, test_size=0.5, stratify=test_df['Final Category'], random_state=42)

# --- TRAIN FINAL CATEGORY MODEL ---
X_train = transform(train_df)
y_train = train_df['Final Category']
X_val = transform(val_df)
y_val = val_df['Final Category']

final_model = LGBMClassifier(class_weight='balanced', random_state=42)
final_model.fit(X_train, y_train, eval_set=[(X_val, y_val)], early_stopping_rounds=5, verbose=10)
joblib.dump(final_model, './saved_model/final_biobert_model.joblib')

# --- INFERENCE ---
X_test = transform(test_df)
predicted = final_model.predict(X_test)
test_df['Predicted'] = predicted
test_df.to_csv('./saved_model/final_biobert_predictions.csv', index=False)

# --- EVALUATION ---
print("\nClassification Report:")
print(classification_report(test_df['Final Category'], test_df['Predicted']))
print("\nConfusion Matrix:")
print(confusion_matrix(test_df['Final Category'], test_df['Predicted']))
print(f"\nF1 Score (weighted): {f1_score(test_df['Final Category'], test_df['Predicted'], average='weighted'):.4f}")
