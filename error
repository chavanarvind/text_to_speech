from azureml.data.datapath import DataPath

# Upload local file to default datastore under 'inputs/'
ws.get_default_datastore().upload_files(
    files=['./data/high_conf_mapping.csv'],  # Local path
    target_path='inputs',                    # Remote folder in Azure
    overwrite=True,
    show_progress=True
)

# Define Azure path to use in pipeline
high_conf_csv_path = DataPath(datastore=ws.get_default_datastore(), path_on_datastore='inputs/high_conf_mapping.csv')
