import os
import glob
import joblib
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OrdinalEncoder, StandardScaler
from sklearn.metrics import classification_report, confusion_matrix, f1_score
from lightgbm import LGBMClassifier, early_stopping, log_evaluation


# --- CONFIG ---
embedding_cache_dir = './saved_model/embeddings'
input_path = './data/target_map_cleaned_non_null_target'
all_files = glob.glob(os.path.join(input_path, '*.parquet'))

# --- Reload data ---
required_cols = ['CMPNT_MATL_DESC', 'CMPNT_MATL_DESC_LEN', 'UNIT_GROUP', 'CMPNT_MATL_TYPE_CATEGORY', 'Final Category']
sample_list = []
for file in all_files:
    df = pd.read_parquet(file, columns=required_cols)
    df = df[df['Final Category'].notna() & df['CMPNT_MATL_DESC'].notna()].copy()
    df['Final Category'] = df['Final Category'].replace({'FNW or CHM': 'FNW_CHM'})
    df.drop_duplicates(inplace=True)
    sampled = df.groupby('Final Category', group_keys=False).apply(lambda x: x.sample(frac=0.1, random_state=42))
    sample_list.append(sampled)

df_all = pd.concat(sample_list, ignore_index=True)

# --- Refit encoders ---
ordinal = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)
scaler = StandardScaler()
ordinal.fit(df_all[['UNIT_GROUP', 'CMPNT_MATL_TYPE_CATEGORY']])
scaler.fit(df_all[['CMPNT_MATL_DESC_LEN']])

# --- Reload splits ---
train_df, temp_df = train_test_split(df_all, test_size=0.2, stratify=df_all['Final Category'], random_state=42)
val_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df['Final Category'], random_state=42)

# --- Function to load cached embeddings ---
def get_cached_embeddings(df):
    split_hash = hash(f"{df.index[0]}_{df.index[-1]}_{len(df)}")
    file = os.path.join(embedding_cache_dir, f"bert_emb_{split_hash}.npy")
    print(f"üìÅ Loading embeddings: {file}")
    desc_emb = np.load(file)
    length_scaled = scaler.transform(df[['CMPNT_MATL_DESC_LEN']])
    cat_encoded = ordinal.transform(df[['UNIT_GROUP', 'CMPNT_MATL_TYPE_CATEGORY']])
    return np.hstack([desc_emb, length_scaled, cat_encoded])

# --- Prepare features and targets ---
X_train = get_cached_embeddings(train_df)
y_train = train_df['Final Category']
X_val = get_cached_embeddings(val_df)
y_val = val_df['Final Category']
X_test = get_cached_embeddings(test_df)
y_test = test_df['Final Category']

# --- Train model ---
model = LGBMClassifier(class_weight='balanced', random_state=42)
model.fit(
    X_train,
    y_train,
    eval_set=[(X_val, y_val)],
    callbacks=[early_stopping(5), log_evaluation(10)]
)
joblib.dump(model, './saved_model/final_biobert_model.joblib')

# --- Inference + Evaluation ---
y_pred = model.predict(X_test)
test_df['Predicted'] = y_pred
test_df.to_csv('./saved_model/final_biobert_predictions.csv', index=False)

# --- Report ---
print("\nClassification Report:")
report = classification_report(y_test, y_pred)
print(report)

print("\nConfusion Matrix:")
print(confusion_matrix(y_test, y_pred))

f1 = f1_score(y_test, y_pred, average='weighted')
print(f"\nF1 Score (weighted): {f1:.4f}")

with open('./saved_model/classification_report.txt', 'w') as f:
    f.write(report)
    f.write(f"\nF1 Score (weighted): {f1:.4f}\n")
