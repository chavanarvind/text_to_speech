import os
import glob
import joblib
import numpy as np
import pandas as pd
from sklearn.preprocessing import OrdinalEncoder, StandardScaler

# --- Load saved encoders (fit them below) ---
ordinal = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)
scaler = StandardScaler()

# --- Paths ---
embedding_dir = './data/validation_step/model_artifects/bert_embedding'
parquet_dir = './data/target_map_cleaned_non_null_target'

# --- Collect all embedded BERT files ---
bert_files = sorted(glob.glob(os.path.join(embedding_dir, '*_bert.npy')))

output_X = []
output_y = []

for bert_file in bert_files:
    try:
        file_name = os.path.basename(bert_file).replace('_bert.npy', '.parquet')
        parquet_file = os.path.join(parquet_dir, file_name)

        if not os.path.exists(parquet_file):
            print(f"⚠️ Missing Parquet for: {file_name}")
            continue

        df = pd.read_parquet(parquet_file, columns=[
            'CMPNT_MATL_DESC_LEN', 'UNIT_GROUP', 'CMPNT_MATL_TYPE_CATEGORY', 'Final Category'
        ])
        df = df[df['Final Category'].notna()]
        df['Final Category'] = df['Final Category'].replace({'FNW or CHM': 'FNW_CHM'})
        df.drop_duplicates(inplace=True)

        # Stratified 60% sample (if needed)
        df = df.groupby('Final Category', group_keys=False).apply(
            lambda x: x.sample(frac=0.6, random_state=42)
        ).reset_index(drop=True)

        desc_emb = np.load(bert_file)
        if len(desc_emb) != len(df):
            print(f"❌ Length mismatch in {file_name}: {len(desc_emb)} vs {len(df)}")
            continue

        df['__bert_emb'] = list(desc_emb)
        output_X.append(df)
        output_y.append(df['Final Category'])

    except Exception as e:
        print(f"❌ Error with {bert_file}: {e}")

# --- Final merge ---
df_all = pd.concat(output_X, ignore_index=True)
print(f"✅ Total samples: {len(df_all)}")

# --- Fit encoders ---
ordinal.fit(df_all[['UNIT_GROUP', 'CMPNT_MATL_TYPE_CATEGORY']])
scaler.fit(df_all[['CMPNT_MATL_DESC_LEN']])

joblib.dump(ordinal, './data/validation_step/model_artifects/ordinal_encoder.pkl')
joblib.dump(scaler, './data/validation_step/model_artifects/scaler.pkl')
print("✅ Encoders saved.")

# --- Final matrix ---
meta_scaled = scaler.transform(df_all[['CMPNT_MATL_DESC_LEN']])
cat_encoded = ordinal.transform(df_all[['UNIT_GROUP', 'CMPNT_MATL_TYPE_CATEGORY']])
bert_array = np.vstack(df_all['__bert_emb'].values)

X_full = np.hstack([bert_array, meta_scaled, cat_encoded])
y_full = df_all['Final Category'].values

np.save('./data/validation_step/model_artifects/X_full.npy', X_full)
np.save('./data/validation_step/model_artifects/y_full.npy', y_full)
print("✅ X_full.npy and y_full.npy created.")
