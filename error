import subprocess
import os
import argparse
import pandas as pd
import numpy as np
import torch
import joblib
import gc
from datetime import datetime
from sentence_transformers import SentenceTransformer
from azureml.core import Run, Model

subprocess.run(["pip", "install", "lightgbm"], check=True)

def log(msg):
    print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] {msg}")

def encode_descriptions(encoder, texts, batch_size=64):
    return encoder.encode(texts, batch_size=batch_size, show_progress_bar=True, convert_to_numpy=True)

def main(input_path, additional_mapped_dir, key_output_dir, final_output_dir):
    run = Run.get_context()
    ws = run.experiment.workspace

    os.makedirs(final_output_dir, exist_ok=True)

    log("üîÅ Loading main category model and encoders...")
    model_dir = Model.get_model_path("RPM_Category_model_full_cat", _workspace=ws)
    model = joblib.load(os.path.join(model_dir, "final_model.joblib"))
    ordinal = joblib.load(os.path.join(model_dir, "ordinal_encoder.pkl"))
    scaler = joblib.load(os.path.join(model_dir, "scaler.pkl"))

    encoder = SentenceTransformer(
        'pritamdeka/BioBERT-mnli-snli-scinli-scitail-mednli-stsb',
        device='cuda' if torch.cuda.is_available() else 'cpu'
    )
    encoder.max_seq_length = 128

    log("üì¶ Loading subcategory models once...")
    subcategory_models = {}
    for cat in ['CHM', 'PKG', 'FNW']:
        model_path = Model.get_model_path(f"RPM_Category_model_full_{cat}_V1", _workspace=ws)
        subcategory_models[cat] = {
            "model": joblib.load(os.path.join(model_path, "final_model.joblib")),
            "encoder": joblib.load(os.path.join(model_path, "ordinal_encoder.pkl")),
            "scaler": joblib.load(os.path.join(model_path, "scaler.pkl")),
        }

    log("üìÅ Loading pre-tagged mapped rows from additional_mapped_dir...")
    mapped_dfs = []
    for f in os.listdir(additional_mapped_dir):
        if f.endswith(".parquet"):
            df = pd.read_parquet(os.path.join(additional_mapped_dir, f))
            df['Score'] = 1.0
            df['prediction_flag'] = 'Mapped_PreExtracted'
            df['inferred_category_model'] = 'direct_mapping'
            df['Final_Prediction'] = df.get('Final Category')
            df['Final Subcategory'] = df.get('Final Subcategory', df.get('Final Category'))
            df['Subcategory_Score'] = 1.0
            df['Subcategory_Model'] = 'direct_mapping'
            df['Predicted_Subcategory'] = df['Final Subcategory']
            df['prediction_flag_subcategory'] = 'Mapped'
            df['source_file'] = f
            mapped_dfs.append(df)

    for f in os.listdir(input_path):
        if not f.endswith(".parquet"):
            continue

        log(f"üîé Processing file: {f}")
        df = pd.read_parquet(os.path.join(input_path, f))
        log(f"üìÑ Total rows in file: {len(df)}")

        df_mapped_direct = df[df['needs_model'].isin([False, 'False', 'false'])].copy()
        log(f"‚úÖ Directly mapped rows (needs_model=False): {len(df_mapped_direct)}")

        if not df_mapped_direct.empty:
            df_mapped_direct['Final_Prediction'] = df_mapped_direct['Final Category']
            df_mapped_direct['Score'] = 1.0
            df_mapped_direct['prediction_flag'] = 'Mapped'
            df_mapped_direct['inferred_category_model'] = 'direct_mapping'
            df_mapped_direct['Final Subcategory'] = df_mapped_direct.get('Final Subcategory', df_mapped_direct['Final Category'])
            df_mapped_direct['Subcategory_Score'] = 1.0
            df_mapped_direct['Subcategory_Model'] = 'direct_mapping'
            df_mapped_direct['Predicted_Subcategory'] = df_mapped_direct['Final Subcategory']
            df_mapped_direct['prediction_flag_subcategory'] = 'Mapped'
            df_mapped_direct['source_file'] = f
        else:
            df_mapped_direct = pd.DataFrame()

        df_pred = df[df['needs_model'].astype(str).str.lower() == 'true'].copy()
        df_needs_category = df_pred[df_pred['Final Category'].isnull()].copy()
        log(f"üß† Rows needing category prediction: {len(df_needs_category)}")

        df_no_category_needed = df_pred[~df_pred.index.isin(df_needs_category.index)].copy()
        df_no_category_needed['Final_Prediction'] = df_no_category_needed['Final Category']

        if not df_needs_category.empty:
            descs = df_needs_category['CMPNT_MATL_DESC_CLEAN'].astype(str).tolist()
            embeddings = encode_descriptions(encoder, descs)

            X = np.hstack([
                embeddings,
                scaler.transform(df_needs_category[['CMPNT_MATL_DESC_LEN']]),
                ordinal.transform(df_needs_category[['UNIT_GROUP', 'CMPNT_MATL_TYPE_CATEGORY']])
            ])

            probs = model.predict_proba(X)
            preds = model.predict(X)
            scores = np.max(probs, axis=1)

            df_needs_category['Score'] = scores
            df_needs_category['Predicted'] = preds
            df_needs_category['Final_Prediction'] = np.where(scores < 0.6, 'Other', preds)
            df_needs_category['prediction_flag'] = np.where(scores < 0.6, 'Low Confidence', 'High Confidence')
            df_needs_category['inferred_category_model'] = 'lightgbm_Bert_RPM_Category_model'

            del descs, embeddings, probs, preds, X
            gc.collect()

        df_combined = pd.concat([df_needs_category, df_no_category_needed], ignore_index=True)

        log(f"üîç Preparing subcategory prediction...")
        subcat_frames = []
        for cat in ['CHM', 'PKG', 'FNW']:
            subset = df_combined[df_combined['Final_Prediction'] == cat].copy()
            if subset.empty:
                continue

            sub_model = subcategory_models[cat]["model"]
            sub_encoder = subcategory_models[cat]["encoder"]
            sub_scaler = subcategory_models[cat]["scaler"]

            descs = subset['CMPNT_MATL_DESC_CLEAN'].astype(str).tolist()
            embeddings = encode_descriptions(encoder, descs)

            X_sub = np.hstack([
                embeddings,
                sub_scaler.transform(subset[['CMPNT_MATL_DESC_LEN']]),
                sub_encoder.transform(subset[['UNIT_GROUP', 'CMPNT_MATL_TYPE_CATEGORY']])
            ])

            probs = sub_model.predict_proba(X_sub)
            preds = sub_model.predict(X_sub)
            scores = np.max(probs, axis=1)

            subset['Final Subcategory'] = np.where(scores < 0.6, 'Other', preds)
            subset['Predicted_Subcategory'] = preds
            subset['Subcategory_Score'] = scores
            subset['prediction_flag_subcategory'] = np.where(scores < 0.6, 'Low Confidence', 'High Confidence')
            subset['Subcategory_Model'] = f"RPM_Category_model_full_{cat}_V1"

            subcat_frames.append(subset)

            del descs, embeddings, probs, preds, X_sub
            gc.collect()

        fallback = df_combined[~df_combined['Final_Prediction'].isin(['CHM', 'PKG', 'FNW'])].copy()
        fallback['Final Subcategory'] = fallback['Final_Prediction']
        fallback['Subcategory_Score'] = 0.9
        fallback['Subcategory_Model'] = 'fallback'
        fallback['prediction_flag_subcategory'] = 'Fallback'
        log(f"üõë Fallback category rows: {len(fallback)}")

        final_df = pd.concat([df_mapped_direct] + subcat_frames + [fallback], ignore_index=True)

        mapped_rows_for_file = [m for m in mapped_dfs if m['source_file'].iloc[0] == f]
        if mapped_rows_for_file:
            pre_mapped_df = pd.concat(mapped_rows_for_file, ignore_index=True)
            final_df = pd.concat([pre_mapped_df, final_df], ignore_index=True)
            pre_mapped_count = len(pre_mapped_df)
        else:
            pre_mapped_count = 0

        directly_mapped_count = len(df_mapped_direct)
        predicted_count = len(final_df) - directly_mapped_count - pre_mapped_count

        log(f"üìä Merged output rows for file {f}:")
        log(f"   üîπ Directly mapped (needs_model=False): {directly_mapped_count}")
        log(f"   üîπ Pre-mapped from additional_mapped_dir: {pre_mapped_count}")
        log(f"   üîπ Predicted via model: {predicted_count}")
        log(f"   üî¢ Total: {len(final_df)}")

        final_df['category_priority'] = final_df['prediction_flag'].map({
            'Mapped_PreExtracted': 2,
            'Mapped': 2,
            'High Confidence': 1,
            'Low Confidence': 0
        }).fillna(0)

        final_df['subcategory_priority'] = final_df['prediction_flag_subcategory'].map({
            'Mapped': 2,
            'High Confidence': 1,
            'Low Confidence': 0,
            'Fallback': -1
        }).fillna(0)

        final_df = final_df.sort_values(
            by=['CMPNT_MATL_NUM', 'category_priority', 'subcategory_priority'],
            ascending=[True, False, False]
        )

        final_df = final_df.drop_duplicates(subset='CMPNT_MATL_NUM', keep='first')
        final_df['source_file'] = f

        output_path = os.path.join(final_output_dir, f"predicted_{f}")
        final_df.to_parquet(output_path, index=False)
        log(f"üíæ Saved prediction: {output_path} (total rows: {len(final_df)})")

        del df, df_pred, df_combined, final_df
        gc.collect()

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--input_path", required=True)
    parser.add_argument("--additional_mapped_dir", required=True)
    parser.add_argument("--key_output_dir", required=True)
    parser.add_argument("--final_output_dir", required=True)
    args = parser.parse_args()

    main(args.input_path, args.additional_mapped_dir, args.key_output_dir, args.final_output_dir)
