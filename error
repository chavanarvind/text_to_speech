import os
import joblib
import torch
import pandas as pd
import numpy as np
from sentence_transformers import SentenceTransformer
from sklearn.preprocessing import OrdinalEncoder, StandardScaler

# --- CONFIGURATION ---
client_file = './data/client_input_file.parquet'  # ‚¨ÖÔ∏è Replace with your file path
output_file = './data/client_predictions.csv'
required_cols = ['CMPNT_MATL_DESC', 'CMPNT_MATL_DESC_LEN', 'UNIT_GROUP', 'CMPNT_MATL_TYPE_CATEGORY']

# --- LOAD CLIENT DATA ---
df = pd.read_parquet(client_file, columns=required_cols)
df = df[df['CMPNT_MATL_DESC'].notna()].copy()
print(f"üì¶ Loaded {len(df)} records from client file.")

# --- LOAD TRAINED ARTIFACTS ---
model_path = './data/validation_step/model_artifects/final_model.joblib'
ordinal_path = './data/validation_step/model_artifects/ordinal_encoder.pkl'
scaler_path = './data/validation_step/model_artifects/scaler.pkl'

model = joblib.load(model_path)
ordinal = joblib.load(ordinal_path)
scaler = joblib.load(scaler_path)

# --- LOAD BERT MODEL ---
device = 'cuda' if torch.cuda.is_available() else 'cpu'
encoder = SentenceTransformer('pritamdeka/BioBERT-mnli-snli-scinli-scitail-mednli-stsb', device=device)
encoder.max_seq_length = 128  # Optional: cap token length

# --- TRANSFORM FEATURES ---
print("üîÑ Generating BERT embeddings...")
desc_texts = df['CMPNT_MATL_DESC'].astype(str).tolist()
desc_emb = encoder.encode(
    desc_texts,
    batch_size=256,
    show_progress_bar=True,
    convert_to_numpy=True,
    num_workers=4
)

length_scaled = scaler.transform(df[['CMPNT_MATL_DESC_LEN']])
cat_encoded = ordinal.transform(df[['UNIT_GROUP', 'CMPNT_MATL_TYPE_CATEGORY']])
X_pred = np.hstack([desc_emb, length_scaled, cat_encoded])

# --- PREDICT ---
print("ü§ñ Predicting with LightGBM model...")
df['Predicted'] = model.predict(X_pred)

# --- SAVE OUTPUT ---
df.to_csv(output_file, index=False)
print(f"‚úÖ Predictions saved to: {output_file}")
