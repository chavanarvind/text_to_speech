import os
import glob
import joblib
import numpy as np
import pandas as pd
from sklearn.preprocessing import OrdinalEncoder, StandardScaler
from concurrent.futures import ProcessPoolExecutor

# --- Define Paths ---
embedding_dir = './data/validation_step/model_artifects/bert_embedding'
parquet_dir = './data/target_map_cleaned_non_null_target'

# --- Collect Files ---
bert_files = sorted(glob.glob(os.path.join(embedding_dir, '*_bert.npy')))

# --- Processing function ---
def process_pair(bert_file):
    try:
        file_name = os.path.basename(bert_file).replace('_bert.npy', '.parquet')
        parquet_file = os.path.join(parquet_dir, file_name)

        if not os.path.exists(parquet_file):
            return None, None

        df = pd.read_parquet(parquet_file, columns=[
            'CMPNT_MATL_DESC_LEN', 'UNIT_GROUP', 'CMPNT_MATL_TYPE_CATEGORY', 'Final Category'
        ])
        df = df[df['Final Category'].notna()]
        df['Final Category'] = df['Final Category'].replace({'FNW or CHM': 'FNW_CHM'})
        df.drop_duplicates(inplace=True)

        df = df.groupby('Final Category', group_keys=False).apply(
            lambda x: x.sample(frac=0.6, random_state=42)
        ).reset_index(drop=True)

        desc_emb = np.load(bert_file)
        if len(desc_emb) != len(df):
            return None, None

        df['__bert_emb'] = list(desc_emb)
        return df, df['Final Category']

    except Exception as e:
        return None, None

# --- Parallel Execution ---
output_X, output_y = [], []
with ProcessPoolExecutor() as executor:
    for df_part, y_part in executor.map(process_pair, bert_files):
        if df_part is not None:
            output_X.append(df_part)
            output_y.append(y_part)

# --- Combine Results ---
df_all = pd.concat(output_X, ignore_index=True)
print(f"✅ Total samples: {len(df_all)}")

# --- Fit and Save Encoders ---
ordinal = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)
scaler = StandardScaler()

ordinal.fit(df_all[['UNIT_GROUP', 'CMPNT_MATL_TYPE_CATEGORY']])
scaler.fit(df_all[['CMPNT_MATL_DESC_LEN']])
joblib.dump(ordinal, './data/validation_step/model_artifects/ordinal_encoder.pkl')
joblib.dump(scaler, './data/validation_step/model_artifects/scaler.pkl')
print("✅ Encoders saved.")

# --- Final Matrix Creation ---
meta_scaled = scaler.transform(df_all[['CMPNT_MATL_DESC_LEN']])
cat_encoded = ordinal.transform(df_all[['UNIT_GROUP', 'CMPNT_MATL_TYPE_CATEGORY']])
bert_array = np.vstack(df_all['__bert_emb'].values)

X_full = np.hstack([bert_array, meta_scaled, cat_encoded])
y_full = df_all['Final Category'].values

np.save('./data/validation_step/model_artifects/X_full.npy', X_full)
np.save('./data/validation_step/model_artifects/y_full.npy', y_full)
print("✅ X_full.npy and y_full.npy created.")
