from azureml.core import Workspace, Dataset, Datastore
from azureml.data.datapath import DataPath

# === Workspace setup (same as your pipeline) ===
SUBSCRIPTION_ID = "a8d518a9-4587-4ba2-9a60-68b980c2f000"
RESOURCE_GROUP = "AZR-WDZ-DTO-AML-Development"
WORKSPACE_NAME = "AML-DTO-Marmot-dev"

# Connect
print("üîå Connecting to Azure ML workspace...")
ws = Workspace(
    subscription_id=SUBSCRIPTION_ID,
    resource_group=RESOURCE_GROUP,
    workspace_name=WORKSPACE_NAME
)

# Get datastore
ds = Datastore.get(ws, "xbomrefadlsg2")

# ‚úÖ Use wildcard to match files
parquet_path = "bom-xref/hbom_category_prediction_inference_per_file/hbom_category_prediction_14062025/*.parquet"

print(f"üîç Trying to access files at: {parquet_path}")
dataset = Dataset.File.from_files(DataPath(ds, parquet_path))

# === Sanity check 1: List file paths (low-level check) ===
try:
    file_paths = dataset._get_path()
    print("‚úÖ Resolved dataset files:")
    for p in file_paths[:10]:
        print("   ‚îî‚îÄ", p)
    if not file_paths:
        print("‚ö†Ô∏è No files matched in the dataset.")
except Exception as e:
    print("‚ùå Failed to list dataset paths.")
    print(e)

# === Sanity check 2: Try downloading 1 sample file ===
try:
    print("‚¨áÔ∏è Downloading sample files...")
    dataset.download(target_path="./preview_data", overwrite=True)
    print("‚úÖ Downloaded sample files to ./preview_data")
except Exception as e:
    print("‚ùå Download failed.")
    print(e)
