----old infarance code
import os
import argparse
import pandas as pd
import numpy as np
import torch
import joblib
import subprocess
import shutil
import time
from datetime import datetime
from azureml.core import Run, Model, Datastore, Dataset, Workspace
from sentence_transformers import SentenceTransformer
from azure.storage.blob import BlobServiceClient
from azure.identity import DefaultAzureCredential
from datetime import datetime
from azure.identity import ChainedTokenCredential, EnvironmentCredential, ManagedIdentityCredential


subprocess.run(["pip", "install", "lightgbm"], check=True)


def log(msg):
    print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] {msg}")



def main(input_path, additional_mapped_dir, key_output_dir):
    
    
    run = Run.get_context()
    ws = run.experiment.workspace

    log("Loading model artifacts...")
    model_dir = Model.get_model_path("RPM_Category_model_full_cat", _workspace=ws)
    model = joblib.load(os.path.join(model_dir, "final_model.joblib"))
    ordinal = joblib.load(os.path.join(model_dir, "ordinal_encoder.pkl"))
    scaler = joblib.load(os.path.join(model_dir, "scaler.pkl"))

    encoder = SentenceTransformer(
        'pritamdeka/BioBERT-mnli-snli-scinli-scitail-mednli-stsb',
        device='cuda' if torch.cuda.is_available() else 'cpu')
    encoder.max_seq_length = 128

    all_results = []
    total_input_rows = 0

    # Load mapped files
    mapped_dfs = []
    for f in os.listdir(additional_mapped_dir):
        if f.endswith(".parquet"):
            df = pd.read_parquet(os.path.join(additional_mapped_dir, f))
            df['Score'] = df.get('Score', 1.0)
            df['prediction_flag'] = df.get('prediction_flag', 'Mapped_PreExtracted')
            df['inferred_category_model'] = df.get('inferred_category_model', 'direct_mapping_step_1a')
            df['Subcategory_Score'] = df.get('Subcategory_Score', 1.0)
            df['Subcategory_Model'] = df.get('Subcategory_Model', 'direct_mapping')
            df['Final_Prediction'] = df.get('Final_Prediction', df.get('Final Category'))
            df['Predicted_Subcategory'] = df.get('Predicted_Subcategory', df.get('Final Subcategory'))
            df['source_file'] = f
            mapped_dfs.append(df)

    if mapped_dfs:
        mapped_combined_df = pd.concat(mapped_dfs, ignore_index=True)
        all_results.append(mapped_combined_df)

    for f in os.listdir(input_path):
        log(f"--- Processing file: {f} ---")
        if not f.endswith(".parquet"): continue
        df_all = pd.read_parquet(os.path.join(input_path, f))
        log(f"[DEBUG] Total rows in file: {len(df_all)}")
        total_input_rows += len(df_all)

        df_mapped = df_all[df_all.get('needs_model') == False].copy()
        df_pred = df_all[df_all.get('needs_model') == True].copy()
        log(f"[DEBUG] Rows with needs_model=True: {len(df_pred)}")

        df_needs_category = df_pred[df_pred['Final Category'].isnull()].copy()
        log(f"[DEBUG] Rows with null Final Category (category prediction needed): {len(df_needs_category)}")
        df_no_category_needed = df_pred[~df_pred.index.isin(df_needs_category.index)].copy()
        df_no_category_needed['Final_Prediction'] = df_no_category_needed['Final Category']

        df_mapped['Final_Prediction'] = df_mapped['Final Category']
        df_mapped['Score'] = 1.0
        df_mapped['prediction_flag'] = 'Mapped'
        df_mapped['inferred_category_model'] = 'direct_mapping'
        df_mapped['Final Subcategory'] = df_mapped['Final Subcategory'] if 'Final Subcategory' in df_mapped.columns else df_mapped['Final Category']
        df_mapped['Subcategory_Score'] = 1.0
        df_mapped['Subcategory_Model'] = 'direct_mapping'
        df_mapped['Predicted_Subcategory'] = df_mapped['Final Subcategory']

        if not df_needs_category.empty:
            log(f"Encoding descriptions for category prediction: {len(df_needs_category)} rows")
            desc_emb = encoder.encode(df_needs_category['CMPNT_MATL_DESC_CLEAN'].astype(str).tolist(),
                                      batch_size=500, show_progress_bar=True, convert_to_numpy=True)
            length_scaled = scaler.transform(df_needs_category[['CMPNT_MATL_DESC_LEN']])
            cat_encoded = ordinal.transform(df_needs_category[['UNIT_GROUP', 'CMPNT_MATL_TYPE_CATEGORY']])
            X_pred = np.hstack([desc_emb, length_scaled, cat_encoded])

            y_proba = model.predict_proba(X_pred)
            y_score = np.max(y_proba, axis=1)
            y_pred = model.predict(X_pred)

            df_needs_category['Score'] = y_score
            df_needs_category['Predicted'] = y_pred
            df_needs_category['Final_Prediction'] = np.where(y_score < 0.6, 'Other', y_pred)
            df_needs_category['prediction_flag'] = np.where(y_score < 0.6, 'Low Confidence', 'High Confidence')
            df_needs_category['inferred_category_model'] = 'lightgbm_Bert_RPM_Category_model'

        df_combined = pd.concat([df_mapped, df_needs_category, df_no_category_needed], ignore_index=True)

        df_sub_mapped = df_combined[df_combined['Final Subcategory'].notna()].copy()
        df_sub_pred = df_combined[df_combined['Final Subcategory'].isna()].copy()
        log(f"[DEBUG] Rows with null Final Subcategory (subcategory prediction needed): {len(df_sub_pred)}")

        subcat_predictions = []
        valid_categories = ['CHM', 'PKG', 'FNW']
        for cat in valid_categories:
            subset = df_sub_pred[df_sub_pred['Final_Prediction'] == cat].copy()
            if not subset.empty:
                log(f"[DEBUG] Running subcategory model for '{cat}': {len(subset)} rows")
                model_path = Model.get_model_path(f"RPM_Category_model_full_{cat}_V1", _workspace=ws)
                sub_model = joblib.load(os.path.join(model_path, "final_model.joblib"))
                sub_encoder = joblib.load(os.path.join(model_path, "ordinal_encoder.pkl"))
                sub_scaler = joblib.load(os.path.join(model_path, "scaler.pkl"))

                desc_emb = encoder.encode(subset['CMPNT_MATL_DESC_CLEAN'].astype(str).tolist(),
                                          batch_size=500, show_progress_bar=True, convert_to_numpy=True)
                length_scaled = sub_scaler.transform(subset[['CMPNT_MATL_DESC_LEN']])
                cat_encoded = sub_encoder.transform(subset[['UNIT_GROUP', 'CMPNT_MATL_TYPE_CATEGORY']])
                X_sub = np.hstack([desc_emb, length_scaled, cat_encoded])

                y_proba_sub = sub_model.predict_proba(X_sub)
                y_score_sub = np.max(y_proba_sub, axis=1)
                y_sub = sub_model.predict(X_sub)

                subset['Final Subcategory'] = np.where(y_score_sub < 0.6, 'Other', y_sub)
                subset['Predicted_Subcategory'] = y_sub
                subset['Subcategory_Score'] = y_score_sub
                subset['prediction_flag_subcategory'] = np.where(y_score_sub < 0.6, 'Low Confidence', 'High Confidence')
                subset['Subcategory_Model'] = f"RPM_Category_model_full_{cat}_V1"
                subcat_predictions.append(subset)

        fallback_rows = df_sub_pred[~df_sub_pred['Final_Prediction'].isin(valid_categories)].copy()
        fallback_rows['Final Subcategory'] = fallback_rows['Final_Prediction']
        fallback_rows['Subcategory_Score'] = 0.9
        fallback_rows['Subcategory_Model'] = 'default_fallback'

        df_sub_mapped['Subcategory_Score'] = 1.0
        df_sub_mapped['Subcategory_Model'] = 'direct_mapping'
        df_sub_mapped['Predicted_Subcategorory'] = df_sub_mapped['Final Subcategory']

        df_sub_pred_final = pd.concat(subcat_predictions + [fallback_rows])
        df_out = pd.concat([df_sub_pred_final, df_sub_mapped], axis=0).sort_index()
        log(f"[DEBUG] Total rows after subcategory + fallback merge: {len(df_out)}")
        df_out['source_file'] = f
        all_results.append(df_out)
    final_df = pd.concat(all_results, ignore_index=True)
    final_df['category_priority'] = final_df['prediction_flag'].map({
    'Mapped_PreExtracted': 2,
    'Mapped': 2,
    'High Confidence': 1,
    'Low Confidence': 0}).fillna(0)

    final_df['subcategory_priority'] = final_df['prediction_flag_subcategory'].map({
    'Mapped': 2,
    'High Confidence': 1,
    'Low Confidence': 0,
    'Fallback': -1}).fillna(0)

    final_df = final_df.sort_values(
    by=['CMPNT_MATL_NUM', 'category_priority', 'subcategory_priority'],
    ascending=[True, False, False])

    final_df = final_df.drop_duplicates(subset='CMPNT_MATL_NUM', keep='first')

    log(f"[INFO] Total original input rows: {total_input_rows}")
    log(f"[INFO] Final prediction row count (after deduplication): {len(final_df)}")

    final_df.to_parquet("outputs/final_prediction_combined.parquet", index=False)
    log("Saved final prediction file")

    # Rename columns
    final_df = final_df.rename(columns={
        "Final_Prediction": "AI_FINAL_CATEGORY",
        "Final Subcategory": "AI_FINAL_SUBCATEGORY",
        "Score": "AI_FINAL_CATEGORY_CONFIDENCE",
        "Subcategory_Score": "AI_FINAL_SUBCATEGORY_CONFIDENCE",
        "inferred_category_model": "AI_MATCHING_REASON_FINAL_CATEGORY",
        "Subcategory_Model": "AI_MATCHING_REASON_FINAL_SUBCATEGORY"
    })

    # Merge with key files
    today = datetime.today().strftime("%d%m%Y")
    mapped_keys_dir = args.final_output_dir
    os.makedirs(mapped_keys_dir, exist_ok=True)
    for key_file in os.listdir(key_output_dir):
        if key_file.endswith(".parquet"):
            key_df = pd.read_parquet(os.path.join(key_output_dir, key_file))
            merged_df = key_df.merge(final_df[[
                "CMPNT_MATL_NUM",
                "AI_FINAL_CATEGORY",
                "AI_FINAL_SUBCATEGORY",
                "AI_FINAL_CATEGORY_CONFIDENCE",
                "AI_FINAL_SUBCATEGORY_CONFIDENCE",
                "AI_MATCHING_REASON_FINAL_CATEGORY",
                "AI_MATCHING_REASON_FINAL_SUBCATEGORY"
            ]], how="left", on="CMPNT_MATL_NUM")
            merged_df.to_parquet(os.path.join(mapped_keys_dir, key_file), index=False)
            print(merged_df.head(5))

            sample_dir = os.path.join("outputs", "samples_by_source")
            os.makedirs(sample_dir, exist_ok=True)
            merged_df[merged_df['AI_MATCHING_REASON_FINAL_SUBCATEGORY'].isin(["RPM_Category_model_full_PKG_V1", "RPM_Category_model_full_CHM_V1"])].head(100).to_csv(
            os.path.join(sample_dir, "merge_rows_subcat.csv"), index=False)
            print(merged_df.columns)
            log(f"Mapped back predictions to key file: {key_file}")
            #  Upload to ADLS Gen2
            #upload_to_adls(file_path=merged_parquet_path, file_name_in_blob=key_file)

    # Save sample CSV for mapped and predicted
    sample_dir = os.path.join("outputs", "samples_by_source")
    os.makedirs(sample_dir, exist_ok=True)
    final_df[final_df['prediction_flag'].str.contains("Mapped", na=False)].head(100).to_csv(
        os.path.join(sample_dir, "sample_mapped_rows.csv"), index=False)
    final_df[final_df['prediction_flag_subcategory'].isin(["High Confidence", "Low Confidence"])].head(100).to_csv(
        os.path.join(sample_dir, "sample_predicted_rows_subcat.csv"), index=False)

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--input_path", required=True)
    parser.add_argument("--additional_mapped_dir", required=True)
    parser.add_argument("--key_output_dir", required=True)
    parser.add_argument("--final_output_dir", required=True)
    args = parser.parse_args()
    main(args.input_path, args.additional_mapped_dir, args.key_output_dir)

----new infarance code
#step_5_run_inference_per_file.py
import subprocess
import os
import argparse
import pandas as pd
import numpy as np
import torch
import joblib
import gc
from datetime import datetime
from sentence_transformers import SentenceTransformer
from azureml.core import Run, Model
subprocess.run(["pip", "install", "lightgbm"], check=True)

def log(msg):
    print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] {msg}")

def encode_descriptions(encoder, texts, batch_size=64):
    return encoder.encode(texts, batch_size=batch_size, show_progress_bar=True, convert_to_numpy=True)

def main(input_path, additional_mapped_dir, key_output_dir, final_output_dir):
    run = Run.get_context()
    ws = run.experiment.workspace

    os.makedirs(final_output_dir, exist_ok=True)

    log("ðŸ” Loading main category model and encoders...")
    model_dir = Model.get_model_path("RPM_Category_model_full_cat", _workspace=ws)
    model = joblib.load(os.path.join(model_dir, "final_model.joblib"))
    ordinal = joblib.load(os.path.join(model_dir, "ordinal_encoder.pkl"))
    scaler = joblib.load(os.path.join(model_dir, "scaler.pkl"))

    encoder = SentenceTransformer(
        'pritamdeka/BioBERT-mnli-snli-scinli-scitail-mednli-stsb',
        device='cuda' if torch.cuda.is_available() else 'cpu'
    )
    encoder.max_seq_length = 128

    log("ðŸ“¦ Loading subcategory models once...")
    subcategory_models = {}
    for cat in ['CHM', 'PKG', 'FNW']:
        model_path = Model.get_model_path(f"RPM_Category_model_full_{cat}_V1", _workspace=ws)
        subcategory_models[cat] = {
            "model": joblib.load(os.path.join(model_path, "final_model.joblib")),
            "encoder": joblib.load(os.path.join(model_path, "ordinal_encoder.pkl")),
            "scaler": joblib.load(os.path.join(model_path, "scaler.pkl")),
        }

    log("ðŸ“ Loading pre-tagged mapped rows from additional_mapped_dir...")
    mapped_dfs = []
    for f in os.listdir(additional_mapped_dir):
        if f.endswith(".parquet"):
            df = pd.read_parquet(os.path.join(additional_mapped_dir, f))
            df['Score'] = 1.0
            df['prediction_flag'] = 'Mapped_PreExtracted'
            df['inferred_category_model'] = 'direct_mapping_step_1a'
            df['Final_Prediction'] = df.get('Final Category')
            df['Final Subcategory'] = df.get('Final Subcategory', df.get('Final Category'))
            df['Subcategory_Score'] = 1.0
            df['Subcategory_Model'] = 'direct_mapping'
            df['Predicted_Subcategory'] = df['Final Subcategory']
            df['prediction_flag_subcategory'] = 'Mapped'
            df['source_file'] = f
            mapped_dfs.append(df)

    for f in os.listdir(input_path):
        if not f.endswith(".parquet"):
            continue

        log(f"ðŸ”Ž Processing file: {f}")
        df = pd.read_parquet(os.path.join(input_path, f))
        log(f"ðŸ“„ Total rows in file: {len(df)}")

        df_mapped_direct = df[df.get('needs_model') == False].copy()
        log(f"âœ… Directly mapped rows (needs_model=False): {len(df_mapped_direct)}")

        if not df_mapped_direct.empty:
            df_mapped_direct['Final_Prediction'] = df_mapped_direct['Final Category']
            df_mapped_direct['Score'] = 1.0
            df_mapped_direct['prediction_flag'] = 'Mapped'
            df_mapped_direct['inferred_category_model'] = 'direct_mapping'
            df_mapped_direct['Final Subcategory'] = df_mapped_direct.get('Final Subcategory', df_mapped_direct['Final Category'])
            df_mapped_direct['Subcategory_Score'] = 1.0
            df_mapped_direct['Subcategory_Model'] = 'direct_mapping'
            df_mapped_direct['Predicted_Subcategory'] = df_mapped_direct['Final Subcategory']
            df_mapped_direct['prediction_flag_subcategory'] = 'Mapped'
            df_mapped_direct['source_file'] = f
        else:
            df_mapped_direct = pd.DataFrame()

        df_pred = df[df.get('needs_model') == True].copy()
        df_needs_category = df_pred[df_pred['Final Category'].isnull()].copy()
        log(f"ðŸ§  Rows needing category prediction: {len(df_needs_category)}")

        df_no_category_needed = df_pred[~df_pred.index.isin(df_needs_category.index)].copy()
        df_no_category_needed['Final_Prediction'] = df_no_category_needed['Final Category']

        if not df_needs_category.empty:
            descs = df_needs_category['CMPNT_MATL_DESC_CLEAN'].astype(str).tolist()
            embeddings = encode_descriptions(encoder, descs)

            X = np.hstack([
                embeddings,
                scaler.transform(df_needs_category[['CMPNT_MATL_DESC_LEN']]),
                ordinal.transform(df_needs_category[['UNIT_GROUP', 'CMPNT_MATL_TYPE_CATEGORY']])
            ])

            probs = model.predict_proba(X)
            preds = model.predict(X)
            scores = np.max(probs, axis=1)

            df_needs_category['Score'] = scores
            df_needs_category['Predicted'] = preds
            df_needs_category['Final_Prediction'] = np.where(scores < 0.6, 'Other', preds)
            df_needs_category['prediction_flag'] = np.where(scores < 0.6, 'Low Confidence', 'High Confidence')
            df_needs_category['inferred_category_model'] = 'lightgbm_Bert_RPM_Category_model'

            del descs, embeddings, probs, preds, X
            gc.collect()

        df_combined = pd.concat([df_needs_category, df_no_category_needed], ignore_index=True)

        log(f"ðŸ” Preparing subcategory prediction...")
        for cat in ['CHM', 'PKG', 'FNW']:
            count = (df_combined['Final_Prediction'] == cat).sum()
            log(f"   â†³ Category {cat}: {count} rows for subcategory model")

        subcat_frames = []
        for cat in ['CHM', 'PKG', 'FNW']:
            subset = df_combined[df_combined['Final_Prediction'] == cat].copy()
            if subset.empty:
                continue

            log(f"   ðŸ”¬ Running subcategory model for: {cat} ({len(subset)} rows)")
            sub_model = subcategory_models[cat]["model"]
            sub_encoder = subcategory_models[cat]["encoder"]
            sub_scaler = subcategory_models[cat]["scaler"]

            descs = subset['CMPNT_MATL_DESC_CLEAN'].astype(str).tolist()
            embeddings = encode_descriptions(encoder, descs)

            X_sub = np.hstack([
                embeddings,
                sub_scaler.transform(subset[['CMPNT_MATL_DESC_LEN']]),
                sub_encoder.transform(subset[['UNIT_GROUP', 'CMPNT_MATL_TYPE_CATEGORY']])
            ])

            probs = sub_model.predict_proba(X_sub)
            preds = sub_model.predict(X_sub)
            scores = np.max(probs, axis=1)

            subset['Final Subcategory'] = np.where(scores < 0.6, 'Other', preds)
            subset['Predicted_Subcategory'] = preds
            subset['Subcategory_Score'] = scores
            subset['prediction_flag_subcategory'] = np.where(scores < 0.6, 'Low Confidence', 'High Confidence')
            subset['Subcategory_Model'] = f"RPM_Category_model_full_{cat}_V1"

            subcat_frames.append(subset)

            del descs, embeddings, probs, preds, X_sub
            gc.collect()

        fallback = df_combined[~df_combined['Final_Prediction'].isin(['CHM', 'PKG', 'FNW'])].copy()
        fallback['Final Subcategory'] = fallback['Final_Prediction']
        fallback['Subcategory_Score'] = 0.9
        fallback['Subcategory_Model'] = 'fallback'
        fallback['prediction_flag_subcategory'] = 'Fallback'
        log(f"ðŸ›‘ Fallback category rows: {len(fallback)}")

        final_df = pd.concat([df_mapped_direct] + subcat_frames + [fallback], ignore_index=True)
        final_df['source_file'] = f

        output_path = os.path.join(final_output_dir, f"predicted_{f}")
        final_df.to_parquet(output_path, index=False)
        log(f"ðŸ’¾ Saved prediction: {output_path} (total rows: {len(final_df)})")

        del df, df_pred, df_combined, final_df
        gc.collect()

    if mapped_dfs:
        mapped_df = pd.concat(mapped_dfs, ignore_index=True)
        mapped_path = os.path.join(final_output_dir, "mapped_combined_result.parquet")
        mapped_df.to_parquet(mapped_path, index=False)
        log(f"ðŸ’¾ Saved mapped combined result: {mapped_path}")

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--input_path", required=True)
    parser.add_argument("--additional_mapped_dir", required=True)
    parser.add_argument("--key_output_dir", required=True)
    parser.add_argument("--final_output_dir", required=True)
    args = parser.parse_args()

    main(args.input_path, args.additional_mapped_dir, args.key_output_dir, args.final_output_dir)
