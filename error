import polars as pl
import pandas as pd
import re
import os
import glob
import time
from concurrent.futures import ThreadPoolExecutor

# Load abbreviation map
abbrev_df = pd.read_csv('./data/abbreviation_expension_updated.csv')
abbrev_map = {k.lower(): v for k, v in zip(abbrev_df['Abbreviation_list'], abbrev_df['Abbreviation_Expension'])}
abbrev_pattern = re.compile(r'\b(' + '|'.join(re.escape(k) for k in abbrev_map.keys()) + r')\b', flags=re.IGNORECASE)

# Text utils
def expand_abbreviations(text):
    if text is None: return text
    return abbrev_pattern.sub(lambda m: abbrev_map[m.group(0).lower()], text)

def clean_text(text):
    if text is None: return text
    text = re.sub(r'[^a-z0-9\s]', ' ', text.lower())
    return re.sub(r'\s+', ' ', text).strip()

def get_unit_group(unit):
    if unit is None: return None
    unit = str(unit).strip().upper()
    chem = {'KG', 'KGS', 'KGA', 'KGW', 'G', 'GR', 'GM', 'MG', 'LB', 'LBS', 'OZ', 'OZA', 'GW', 'TON', 'DR'}
    liquid = {'L', 'LT', 'ML', 'CC', 'CL', 'CCM', 'GLL'}
    discrete = {'EA', 'PC', 'PCS', 'PKT', 'PK', 'PAK', 'PCK', 'CS', 'CSE', 'CT', 'CA', 'ST', 'GRO', 'BX'}
    containers = {'BOT', 'BOTTLE', 'ROLL', 'ROL', 'REEL', 'KAR'}
    dimensional = {'FT', 'YD', 'KM', 'DM', 'M', 'M1', 'M2', 'KM2', 'YD2', 'FT3', 'SQM', 'MYD', 'MI', 'SM', 'LM', 'LF', 'MH', 'KN', 'CH'}
    return (
        'CHM' if unit in chem else
        'Liquid' if unit in liquid else
        'Discrete' if unit in discrete else
        'Containers' if unit in containers else
        'Dimensional' if unit in dimensional else
        'Unclassified'
    )

# Required input columns
required_cols = [
    'CMPNT_CAT_CD_DESC',
    'CMPNT_MATL_DESC',
    'CMPNT_MATL_TYPE_CD',
    'CMPNT_UOM_CD',
    'Final Category',
    'MATL_SHRT_DESC'
]

# Processing function
def process_file(file):
    try:
        print(f"\n📁 Processing: {os.path.basename(file)}")
        start = time.time()

        df = pl.read_parquet(file)

        # Keep only required columns
        df = df.select([col for col in required_cols if col in df.columns])

        # Convert to dicts for row-wise text transformation
        df_dicts = df.to_dicts()

        for row in df_dicts:
            row['MATL_SHRT_DESC'] = clean_text(expand_abbreviations(row.get('MATL_SHRT_DESC')))
            row['CMPNT_MATL_DESC'] = clean_text(expand_abbreviations(row.get('CMPNT_MATL_DESC')))
            row['MATL_SHRT_DESC_AND_CMPNT_MATL_DESC'] = (
                ((row['MATL_SHRT_DESC'] or '') + ' ' + (row['CMPNT_MATL_DESC'] or '')).strip() or None
            )
            cat_desc = row.get('CMPNT_CAT_CD_DESC')
            row['CMPNT_CAT_CLEAN'] = clean_text(cat_desc.lower()) if cat_desc else None
            row['UNIT_GROUP'] = get_unit_group(row.get('CMPNT_UOM_CD'))

        # Ensure consistent string typing
        all_cols = list(set(required_cols + ['MATL_SHRT_DESC_AND_CMPNT_MATL_DESC', 'CMPNT_CAT_CLEAN', 'UNIT_GROUP']))
        safe_rows = [
            {col: str(row.get(col)) if row.get(col) is not None else None for col in all_cols}
            for row in df_dicts
        ]

        new_df = pl.DataFrame(safe_rows)

        # Overwrite the same file
        new_df.write_parquet(file)
        print(f"✅ Updated: {os.path.basename(file)} | ⏱️ Time: {time.time() - start:.2f}s")

    except Exception as e:
        print(f"❌ Error: {os.path.basename(file)} -> {e}")

# Run in parallel
input_path = './data/target_map_parquet_files'
files = glob.glob(os.path.join(input_path, '*.parquet'))

with ThreadPoolExecutor(max_workers=4) as executor:
    executor.map(process_file, files)
