import os
import glob
import numpy as np
import pandas as pd
import torch
from sentence_transformers import SentenceTransformer

# Setup
input_path = './data/target_map_cleaned_non_null_target'
embedding_dir = './data/validation_step/model_artifects/bert_embedding'
sample_dir = './data/validation_step/model_artifects/sampled_rows'
os.makedirs(embedding_dir, exist_ok=True)
os.makedirs(sample_dir, exist_ok=True)

encoder = SentenceTransformer(
    'pritamdeka/BioBERT-mnli-snli-scinli-scitail-mednli-stsb',
    device='cuda' if torch.cuda.is_available() else 'cpu'
)

category_frac_map = {
    'CHM': 0.05, 'PKG': 0.05, 'FNW': 0.1, 'FNW_CHM': 0.3,
    'Liquids and Creams': 0.5, 'API': 1.0
}

# Select only 2 files
files = sorted(glob.glob(os.path.join(input_path, '*.parquet')))[:2]

for file in files:
    file_name = os.path.splitext(os.path.basename(file))[0]
    bert_path = os.path.join(embedding_dir, f'{file_name}_bert.npy')
    sample_path = os.path.join(sample_dir, f'{file_name}_sampled.parquet')

    try:
        df = pd.read_parquet(file)
        df = df[df['CMPNT_MATL_DESC'].notna()]
        df['Final Category'] = df['Final Category'].replace({'FNW or CHM': 'FNW_CHM'})
        df = df.drop_duplicates(subset=['CMPNT_MATL_DESC', 'Final Category'])

        sampled = (
            df.groupby('Final Category', group_keys=False)
              .apply(lambda g: g.sample(frac=category_frac_map.get(g.name, 0.1), random_state=42))
              .reset_index(drop=True)
        )

        if sampled.empty:
            print(f"⚠️ Skipping {file_name}: no valid sampled rows")
            continue

        # Embed
        desc_emb = encoder.encode(
            sampled['CMPNT_MATL_DESC'].astype(str).tolist(),
            batch_size=256,
            show_progress_bar=True,
            convert_to_numpy=True,
            num_workers=4
        )

        if len(desc_emb) != len(sampled):
            print(f"❌ Skipped {file_name}: embedding length mismatch")
            continue

        np.save(bert_path, desc_emb)
        sampled.to_parquet(sample_path, index=False)
        print(f"✅ Saved: {file_name} ({len(sampled)} samples)")

    except Exception as e:
        print(f"❌ Error in {file_name}: {e}")
