# step_6_finalize_output_optimized.py

import os
import argparse
import pandas as pd
from datetime import datetime
from azureml.core import Run

def log(msg):
    print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] {msg}")

REQUIRED_COLUMNS = [
    "CMPNT_MATL_NUM",
    "Final_Prediction",
    "Final Subcategory",
    "Score",
    "Subcategory_Score",
    "inferred_category_model",
    "Subcategory_Model"
]

RENAMED_COLUMNS = {
    "Final_Prediction": "AI_FINAL_CATEGORY",
    "Final Subcategory": "AI_FINAL_SUBCATEGORY",
    "Score": "AI_FINAL_CATEGORY_CONFIDENCE",
    "Subcategory_Score": "AI_FINAL_SUBCATEGORY_CONFIDENCE",
    "inferred_category_model": "AI_MATCHING_REASON_FINAL_CATEGORY",
    "Subcategory_Model": "AI_MATCHING_REASON_FINAL_SUBCATEGORY"
}

def apply_priority_and_deduplicate(df):
    df['category_priority'] = df['prediction_flag'].map({
        'Mapped_PreExtracted': 2,
        'Mapped': 2,
        'High Confidence': 1,
        'Low Confidence': 0
    }).fillna(0)

    df['subcategory_priority'] = df['prediction_flag_subcategory'].map({
        'Mapped': 2,
        'High Confidence': 1,
        'Low Confidence': 0,
        'Fallback': -1
    }).fillna(0)

    df = df.sort_values(
        by=['CMPNT_MATL_NUM', 'category_priority', 'subcategory_priority'],
        ascending=[True, False, False]
    )
    return df.drop_duplicates(subset="CMPNT_MATL_NUM", keep="first")

def main(inference_output_dir, key_output_dir, final_output_dir):
    run = Run.get_context()

    os.makedirs(final_output_dir, exist_ok=True)
    log(f"üîç Starting per-file processing...")

    for file in os.listdir(inference_output_dir):
        if not file.endswith(".parquet"):
            continue

        inf_path = os.path.join(inference_output_dir, file)
        key_path = os.path.join(key_output_dir, file)

        if not os.path.exists(key_path):
            log(f"‚ö†Ô∏è Skipping: No key file for {file}")
            continue

        log(f"üìÑ Processing inference file: {file}")
        df = pd.read_parquet(inf_path)
        df = apply_priority_and_deduplicate(df)
        df = df[REQUIRED_COLUMNS].rename(columns=RENAMED_COLUMNS)

        key_df = pd.read_parquet(key_path).drop_duplicates()
        merged = key_df.merge(df, how="left", on="CMPNT_MATL_NUM")

        out_path = os.path.join(final_output_dir, file)
        merged.to_parquet(out_path, index=False)
        log(f"‚úÖ Saved merged file: {out_path}")

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--inference_output_dir", required=True)
    parser.add_argument("--key_output_dir", required=True)
    parser.add_argument("--final_output_dir", required=True)
    args = parser.parse_args()

    main(args.inference_output_dir, args.key_output_dir, args.final_output_dir)
