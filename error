import os
import glob
import re
import pandas as pd
import spacy
from multiprocessing import Pool, cpu_count

# Load spaCy model globally once per process
nlp = spacy.load("en_core_web_sm")

# --- RULE_HINT ---
def get_rule_hint(text):
    if pd.isna(text):
        return None
    doc = nlp(text)
    lemmas = set(token.lemma_ for token in doc)

    if lemmas & {'api', 'active'}:
        return 'API'
    elif lemmas & {'cream', 'gel', 'emulsion', 'ointment', 'moisturiser'}:
        return 'Liquids and Creams'
    elif lemmas & {'bottle', 'cap', 'carton', 'label', 'cotton', 'lotion', 'mouthwash', 'pkg', 'pack', 'karton', 'package'}:
        return 'PKG'
    elif lemmas & {'excipient', 'binder', 'bind', 'filler', 'fill', 'lubricant', 'lubricate', 'acid'}:
        return 'CHM'
    return None

# --- Flat UNIT_GROUP mapping for fast .map() ---
unit_group_map = {
    'KG': 'CHM', 'KGS': 'CHM', 'KGA': 'CHM', 'KGW': 'CHM', 'G': 'CHM', 'GR': 'CHM', 'GM': 'CHM', 'MG': 'CHM',
    'LB': 'CHM', 'LBS': 'CHM', 'OZ': 'CHM', 'OZA': 'CHM', 'GW': 'CHM', 'TON': 'CHM', 'DR': 'CHM',
    'L': 'Liquid', 'LT': 'Liquid', 'ML': 'Liquid', 'CC': 'Liquid', 'CL': 'Liquid', 'CCM': 'Liquid', 'GLL': 'Liquid',
    'EA': 'Discrete', 'PC': 'Discrete', 'PCS': 'Discrete', 'Pcs': 'Discrete', 'PKT': 'Discrete', 'PK': 'Discrete',
    'PAK': 'Discrete', 'PCK': 'Discrete', 'CS': 'Discrete', 'CSE': 'Discrete', 'CT': 'Discrete', 'CA': 'Discrete',
    'ST': 'Discrete', 'GRO': 'Discrete', 'BX': 'Discrete',
    'BOT': 'Containers', 'BOTTLE': 'Containers', 'ROLL': 'Containers', 'ROL': 'Containers', 'REEL': 'Containers',
    'KAR': 'Containers',
    'FT': 'Dimensional', 'YD': 'Dimensional', 'KM': 'Dimensional', 'DM': 'Dimensional', 'M': 'Dimensional',
    'M1': 'Dimensional', 'M2': 'Dimensional', 'KM2': 'Dimensional', 'YD2': 'Dimensional', 'FT3': 'Dimensional',
    'SQM': 'Dimensional', 'sqm': 'Dimensional', 'MYD': 'Dimensional', 'MI': 'Dimensional', 'SM': 'Dimensional',
    'LM': 'Dimensional', 'LF': 'Dimensional', 'MH': 'Dimensional', 'KN': 'Dimensional', 'CH': 'Dimensional',
    'TH': 'Unclassified', 'THU': 'Unclassified', 'IM': 'Unclassified', 'NOS': 'Unclassified', 'NO': 'Unclassified',
    'TS': 'Unclassified', 'KA': 'Unclassified', 'ZPC': 'Unclassified', 'ZCT': 'Unclassified', '0%': 'Unclassified',
    'KP': 'Unclassified', 'GP': 'Unclassified', 'KAI': 'Unclassified', 'SY': 'Unclassified', 'UN': 'Unclassified',
    'MU': 'Unclassified', 'UM': 'Unclassified', 'HU': 'Unclassified'
}

# --- Per-file processing function ---
def process_file(file):
    try:
        df = pd.read_parquet(file)

        # Vectorized clean CMPNT_CAT_CLEAN
        df['CMPNT_CAT_CLEAN'] = (
            df['CMPNT_CAT_CD_DESC']
            .fillna('')
            .str.lower()
            .str.replace(r'[^a-z0-9\s]', ' ', regex=True)
            .str.replace(r'\s+', ' ', regex=True)
            .str.strip()
            .replace('', pd.NA)
        )

        # RULE_HINT (NLP-based)
        df['RULE_HINT'] = df['CMPNT_CAT_CLEAN'].apply(get_rule_hint)

        # UNIT_GROUP (vectorized with map)
        df['UNIT_GROUP'] = (
            df['CMPNT_UOM_CD']
            .fillna('')
            .str.upper()
            .map(unit_group_map)
            .fillna('Unclassified')
        )

        # Save to new folder
        output_file = file.replace("target_map_cleaned", "target_map_with_rules")
        os.makedirs(os.path.dirname(output_file), exist_ok=True)
        df.to_parquet(output_file, index=False)

        print(f"✅ Done: {os.path.basename(file)}")
    except Exception as e:
        print(f"❌ Failed: {os.path.basename(file)} -> {e}")

# --- Entry point ---
if __name__ == '__main__':
    input_path = './data/target_map_cleaned'
    all_files = glob.glob(os.path.join(input_path, '*.parquet'))

    with Pool(processes=cpu_count()) as pool:
        pool.map(process_file, all_files)
