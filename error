import os
import re
import time
import glob
import pandas as pd
from concurrent.futures import ThreadPoolExecutor
from threading import Lock

# --- Precompiled regex patterns ---
patterns = {
    'non_alphanumeric': re.compile(r'[^A-Za-z0-9&% ]+'),
    'percent_space': re.compile(r"\s*%\s*"),
    'canada_variants': re.compile(r'(canada|can|(ca\d+)$|ca)'),
    'remove_canada': re.compile(r'canada\s*(\d{2,})|(canada\d+)|canada|can\s*(\d{2,})|(can\d+)|can|(ca\d+)|ca\s(\d{2,})|ca$|(ca\s)'),
    'units': re.compile(r"(\D)(\d+)(\s*)(ml|l|gr|gm|g|ct)"),
    'spf_space': re.compile(r"(\s)(spf)\s*([\d+])"),
    'units_no_space': re.compile(r'([\d+])\s*(?:ml|l|gr|gm|g|ct)(?: |$)'),
    'spf_number': re.compile(r"(\D)(spf\d+)")
}

# --- Clean Series ---
def clean_series(series):
    return (series.str.lower()
        .str.replace(patterns['non_alphanumeric'], '', regex=True)
        .str.replace(patterns['percent_space'], '% ', regex=True)
        .str.replace(patterns['canada_variants'], r' \1', regex=True)
        .str.replace(patterns['remove_canada'], '', regex=True)
        .str.replace(patterns['units'], r'\1 \2\3\4 ', regex=True)
        .str.replace(patterns['spf_space'], r'\1\2\3', regex=True)
        .str.replace(patterns['units_no_space'], lambda z: z.group().replace(" ", ""), regex=True)
        .str.replace(patterns['spf_number'], r'\1 \2 ', regex=True)
    )

# --- Shared progress tracking ---
counter = 0
lock = Lock()
start_time = time.time()

# --- File processing ---
def text_clean_step(file, total_files):
    global counter
    try:
        df = pd.read_parquet(file)

        df['MATL_SHRT_DESC'] = clean_series(df['MATL_SHRT_DESC'].fillna(''))
        df['CMPNT_MATL_DESC'] = clean_series(df['CMPNT_MATL_DESC'].fillna(''))

        df['MATL_SHRT_DESC_AND_CMPNT_MATL_DESC'] = (
            df['MATL_SHRT_DESC'] + ' ' + df['CMPNT_MATL_DESC']
        ).str.strip()

        # Save to original file (optional: change to write elsewhere)
        df.to_parquet(file, index=False)

    except Exception as e:
        with lock:
            with open('failures.log', 'a') as log:
                log.write(f"{file} -> {e}\n")
        print(f" Failed: {os.path.basename(file)} -> {e}")
    finally:
        with lock:
            counter += 1
            elapsed = time.time() - start_time
            percent_remaining = 100 * (total_files - counter) / total_files
            avg_time = elapsed / counter
            eta = avg_time * (total_files - counter)
            print(f" Done: {os.path.basename(file)} | {counter}/{total_files} completed "
                  f"({percent_remaining:.2f}% remaining, ETA: {eta:.1f}s)")

# --- Setup & execution ---
input_path = './data/target_map_parquet_files'
max_workers = 8  #  Change as needed

all_files = glob.glob(os.path.join(input_path, '*.parquet'))
total_files = len(all_files)

with ThreadPoolExecutor(max_workers=max_workers) as executor:
    for file in all_files:
        executor.submit(text_clean_step, file, total_files)
