from sklearn.utils.class_weight import compute_class_weight
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import SGDClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OrdinalEncoder, StandardScaler
from sklearn.metrics import log_loss, accuracy_score, classification_report, top_k_accuracy_score
from scipy.sparse import hstack
import pandas as pd
import numpy as np
import glob
import os

# Setup
input_path = './data/target_map_cleaned_non_null_target'
all_files = glob.glob(os.path.join(input_path, '*.parquet'))

# Load a sample for fitting
sample_data = pd.concat([pd.read_parquet(f) for f in all_files[:2]], ignore_index=True)
sample_data = sample_data[sample_data['Final Category'].notna()].copy()
sample_data['Final Category'] = sample_data['Final Category'].replace({'FNW or CHM': 'FNW_CHM'})

# Prepare encoders and scalers (only CMPNT_MATL_DESC and structured features)
text_vec = TfidfVectorizer(ngram_range=(1, 2), max_features=2**14)
ordinal_enc = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)
scaler = StandardScaler()

# Fit on sample
text_vec.fit(sample_data['CMPNT_MATL_DESC'].astype(str))
ordinal_enc.fit(sample_data[['UNIT_GROUP', 'CMPNT_MATL_TYPE_CATEGORY']])
scaler.fit(sample_data[['CMPNT_MATL_DESC_LEN']])

# Class weights
classes = np.unique(sample_data['Final Category'])
class_weights_arr = compute_class_weight(class_weight='balanced', classes=classes, y=sample_data['Final Category'])
class_weight_dict = dict(zip(classes, class_weights_arr))

# Validation set
X_sample = sample_data[[
    'CMPNT_MATL_DESC',
    'CMPNT_MATL_DESC_LEN',
    'UNIT_GROUP', 'CMPNT_MATL_TYPE_CATEGORY'
]]
y_sample = sample_data['Final Category']
X_train, X_val, y_train, y_val = train_test_split(X_sample, y_sample, stratify=y_sample, test_size=0.2, random_state=42)

# Transform validation data
X_val_trans = hstack([
    text_vec.transform(X_val['CMPNT_MATL_DESC'].astype(str)),
    scaler.transform(X_val[['CMPNT_MATL_DESC_LEN']]),
    ordinal_enc.transform(X_val[['UNIT_GROUP', 'CMPNT_MATL_TYPE_CATEGORY']])
])

# Initialize classifier
clf = SGDClassifier(loss='log_loss', max_iter=1, tol=None, warm_start=True,
                    random_state=42, class_weight=class_weight_dict)

# Training loop
best_loss = float('inf')
no_improve_count = 0
patience = 2
n_epochs = 10

for epoch in range(1, n_epochs + 1):
    print(f"\nüîÅ Epoch {epoch}")
    for file in all_files:
        df = pd.read_parquet(file)
        df = df[df['Final Category'].notna()].copy()
        df['Final Category'] = df['Final Category'].replace({'FNW or CHM': 'FNW_CHM'})

        X_batch = df[[
            'CMPNT_MATL_DESC',
            'CMPNT_MATL_DESC_LEN',
            'UNIT_GROUP', 'CMPNT_MATL_TYPE_CATEGORY'
        ]]
        y_batch = df['Final Category']

        X_batch_trans = hstack([
            text_vec.transform(X_batch['CMPNT_MATL_DESC'].astype(str)),
            scaler.transform(X_batch[['CMPNT_MATL_DESC_LEN']]),
            ordinal_enc.transform(X_batch[['UNIT_GROUP', 'CMPNT_MATL_TYPE_CATEGORY']])
        ])

        clf.partial_fit(X_batch_trans, y_batch, classes=classes)

    y_val_proba = clf.predict_proba(X_val_trans)
    val_loss = log_loss(y_val, y_val_proba, labels=classes)
    val_acc = accuracy_score(y_val, clf.predict(X_val_trans))
    val_top3 = top_k_accuracy_score(y_val, y_val_proba, k=3, labels=classes)

    print(f"üìò Val Loss = {val_loss:.4f} | Top-1 Acc = {val_acc:.4f} | Top-3 Acc = {val_top3:.4f}")

    if val_loss < best_loss - 1e-4:
        best_loss = val_loss
        best_model = clf
        no_improve_count = 0
    else:
        no_improve_count += 1
        if no_improve_count >= patience:
            print(f"üõë Early stopping at epoch {epoch}")
            break

# Final classification report
print("\nüìä Final Classification Report:")
print(classification_report(y_val, best_model.predict(X_val_trans), digits=3))
