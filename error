        # Check required column exists
        if 'Final Category' not in df.columns:
            print(f"‚ö†Ô∏è Skipping {file_name}: 'Final Category' column missing.")
            continue

        # Stratified sample with category-specific fraction
        df_sampled = (
            df.groupby('Final Category', group_keys=False)
            .apply(lambda g: g.sample(
                frac=category_frac_map.get(g.name, 0.1),
                random_state=42
            ), include_groups=False)
            .reset_index(drop=True)
        )

        if df_sampled.empty:
            print(f"‚ö†Ô∏è Skipping {file_name}: No valid rows after sampling")
            continue

        df_sampled.to_parquet(sample_cache_file, index=False)

        if os.path.exists(bert_cache_file):
            print(f"üîÅ Skipping {file_name}: already embedded.")
            desc_emb = np.load(bert_cache_file)
        else:
            print(f"üîÑ Generating embeddings for: {file_name} ({len(df_sampled)} rows)")
            desc_texts = df_sampled['CMPNT_MATL_DESC'].astype(str).tolist()
            desc_emb = encoder.encode(
                desc_texts,
                batch_size=128,
                show_progress_bar=True,
                convert_to_numpy=True,
                num_workers=4
            )
            np.save(bert_cache_file, desc_emb)

        if len(desc_emb) != len(df_sampled):
            print(f"‚ùå Mismatch in {file_name}: {len(desc_emb)} embeddings vs {len(df_sampled)} rows. Skipping.")
            continue

        df_sampled['__bert_emb'] = list(desc_emb)
        output_X.append(df_sampled)
        output_y.append(df_sampled['Final Category'])

    except Exception as e:
        print(f"‚ùå Error processing {file_name}: {e}")

# --- COMBINE ALL DATA ---
if not output_X:
    raise RuntimeError("‚ùå No valid data processed. Ensure .npy and .parquet files match.")

df_all = pd.concat(output_X, ignore_index=True)
print(f"\n‚úÖ Total records after merge: {len(df_all)}")

# --- FIT AND SAVE ENCODERS ---
ordinal.fit(df_all[['UNIT_GROUP', 'CMPNT_MATL_TYPE_CATEGORY']])
scaler.fit(df_all[['CMPNT_MATL_DESC_LEN']])
joblib.dump(ordinal, os.path.join(output_dir, 'ordinal_encoder.pkl'))
joblib.dump(scaler, os.path.join(output_dir, 'scaler.pkl'))
print("‚úÖ OrdinalEncoder and Scaler saved.")

# --- FINAL FEATURE MATRIX ---
meta_scaled = scaler.transform(df_all[['CMPNT_MATL_DESC_LEN']])
cat_encoded = ordinal.transform(df_all[['UNIT_GROUP', 'CMPNT_MATL_TYPE_CATEGORY']])
bert_array = np.vstack(df_all['__bert_emb'].values)

X_full = np.hstack([bert_array, meta_scaled, cat_encoded])
y_full = df_all['Final Category'].values

np.save(os.path.join(output_dir, 'X_full.npy'), X_full)
np.save(os.path.join(output_dir, 'y_full.npy'), y_full)
print("‚úÖ Final BERT+Meta feature matrix saved.")
