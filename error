import os
import argparse
import pandas as pd
import numpy as np
import torch
import joblib
import subprocess
from datetime import datetime
from azureml.core import Run, Model
from sentence_transformers import SentenceTransformer
from azureml.core import Run, Datastore, Dataset, Workspace
import time
import shutil

subprocess.run(["pip", "install", "lightgbm"], check=True)

def log(msg):
    print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] {msg}")

def main(input_path, additional_mapped_dir):
    run = Run.get_context()
    ws = run.experiment.workspace

    log(" Loading model artifacts...")
    model_dir = Model.get_model_path("RPM_Category_model_full_cat", _workspace=ws)
    model = joblib.load(os.path.join(model_dir, "final_model.joblib"))
    ordinal = joblib.load(os.path.join(model_dir, "ordinal_encoder.pkl"))
    scaler = joblib.load(os.path.join(model_dir, "scaler.pkl"))

    encoder = SentenceTransformer(
        'pritamdeka/BioBERT-mnli-snli-scinli-scitail-mednli-stsb',
        device='cuda' if torch.cuda.is_available() else 'cpu'
    )
    encoder.max_seq_length = 128

    log(" Scanning input files...")
    files = [f for f in os.listdir(input_path) if f.endswith(".parquet")]
    log(f" Found {len(files)} files to process.")

    all_results = []

    log(f" Loading pre-mapped data from: {additional_mapped_dir}")
    mapped_files = [f for f in os.listdir(additional_mapped_dir) if f.endswith(".parquet")]
    mapped_dfs = []
    for f in mapped_files:
        df = pd.read_parquet(os.path.join(additional_mapped_dir, f))

        required_cols_defaults = {
            'Score': 1.0,
            'Predicted': None,
            'Final_Prediction': None,
            'Subcategory_Score': 1.0,
            'Subcategory_Model': 'direct_mapping',
            'Predicted_Subcategory': None,
            'prediction_flag': 'Mapped_PreExtracted',
            'inferred_category_model': 'direct_mapping_step_1a'
        }

        for col, default in required_cols_defaults.items():
            if col not in df.columns:
                df[col] = default

        if 'Final_Prediction' not in df.columns or df['Final_Prediction'].isnull().all():
            df['Final_Prediction'] = df.get('Final Category', None)
        if 'Predicted_Subcategory' not in df.columns or df['Predicted_Subcategory'].isnull().all():
            df['Predicted_Subcategory'] = df.get('Final Subcategory', None)

        df['source_file'] = f
        mapped_dfs.append(df)

    if mapped_dfs:
        mapped_combined_df = pd.concat(mapped_dfs, ignore_index=True)
        all_results.append(mapped_combined_df)
        log(f" Loaded and added {len(mapped_combined_df)} mapped rows from step_1a.")
    else:
        log(" No additional mapped data found.")

    for f in files:
        log(f"Processing file: {f}")
        file_path = os.path.join(input_path, f)
        df_all = pd.read_parquet(file_path)
        log(f" Original row count: {len(df_all)}")

        if 'CMPNT_MATL_NUM' not in df_all.columns:
            log(f" Skipping {f}: 'CMPNT_MATL_NUM' column not found.")
            continue

        if 'needs_model' in df_all.columns:
            df_mapped = df_all[df_all['needs_model'] == False].copy()
            df_pred = df_all[df_all['needs_model'] == True].copy()
        else:
            df_mapped = pd.DataFrame(columns=df_all.columns)
            df_pred = df_all.copy()

        df_mapped['Final_Prediction'] = df_mapped['Final Category']
        df_mapped['Score'] = 1.0
        df_mapped['prediction_flag'] = 'Mapped'
        df_mapped['inferred_category_model'] = 'direct_mapping'

        if not df_pred.empty:
            log(f" Rows needing prediction: {len(df_pred)}")
            log(" Encoding descriptions with BERT...")
            desc_emb = encoder.encode(
                df_pred['CMPNT_MATL_DESC_CLEAN'].astype(str).tolist(),
                batch_size=256,
                show_progress_bar=True,
                convert_to_numpy=True)

            log("⚙️ Transforming structured features...")
            length_scaled = scaler.transform(df_pred[['CMPNT_MATL_DESC_LEN']])
            cat_encoded = ordinal.transform(df_pred[['UNIT_GROUP', 'CMPNT_MATL_TYPE_CATEGORY']])
            X_pred = np.hstack([desc_emb, length_scaled, cat_encoded])

            log(" Predicting categories...")
            y_proba = model.predict_proba(X_pred)
            y_score = np.max(y_proba, axis=1)
            y_pred = model.predict(X_pred)

            df_pred['Score'] = y_score
            df_pred['Predicted'] = y_pred
            df_pred['Final_Prediction'] = np.where(y_score < 0.6, 'Other', y_pred)
            df_pred['prediction_flag'] = np.where(y_score < 0.6, 'Low Confidence', 'High Confidence')
            df_pred['inferred_category_model'] = 'lightgbm_Bert_RPM_Category_model'

            log(f"Finished prediction. High-confidence rows: {(y_score >= 0.6).sum()}")

        df_out = pd.concat([df_pred, df_mapped], axis=0).sort_index()

        log(" Predicting subcategories for missing values...")
        df_sub_mapped = df_out[df_out['Final Subcategory'].notna()].copy()
        df_sub_pred = df_out[df_out['Final Subcategory'].isna()].copy()

        subcat_predictions = []
        valid_categories = ['CHM', 'PKG', 'FNW']
        for cat in valid_categories:
            subset = df_sub_pred[df_sub_pred['Final_Prediction'] == cat].copy()
            if not subset.empty:
                log(f" Subcategory prediction for {cat}: {len(subset)} rows")
                model_name = f"RPM_Category_model_full_{cat}_V1"
                model_path = Model.get_model_path(model_name, _workspace=ws)
                sub_model = joblib.load(os.path.join(model_path, "final_model.joblib"))
                sub_encoder = joblib.load(os.path.join(model_path, "ordinal_encoder.pkl"))
                sub_scaler = joblib.load(os.path.join(model_path, "scaler.pkl"))

                desc_emb = encoder.encode(
                    subset['CMPNT_MATL_DESC_CLEAN'].astype(str).tolist(),
                    batch_size=256,
                    show_progress_bar=True,
                    convert_to_numpy=True)

                length_scaled = sub_scaler.transform(subset[['CMPNT_MATL_DESC_LEN']])
                cat_encoded = sub_encoder.transform(subset[['UNIT_GROUP', 'CMPNT_MATL_TYPE_CATEGORY']])
                X_sub = np.hstack([desc_emb, length_scaled, cat_encoded])
                y_sub = sub_model.predict(X_sub)
                subset['Final Subcategory'] = y_sub
                subset['Predicted_Subcategory'] = y_sub
                subset['Subcategory_Score'] = 0.9
                subset['Subcategory_Model'] = model_name
                subcat_predictions.append(subset)

        fallback_rows = df_sub_pred[~df_sub_pred['Final_Prediction'].isin(valid_categories)].copy()
        fallback_rows['Final Subcategory'] = fallback_rows['Final_Prediction']
        fallback_rows['Subcategory_Score'] = 0.9
        fallback_rows['Subcategory_Model'] = 'default_fallback'

        df_sub_mapped['Subcategory_Score'] = 1.0
        df_sub_mapped['Subcategory_Model'] = 'direct_mapping'
        df_sub_mapped['Predicted_Subcategory'] = df_sub_mapped['Final Subcategory']

        df_sub_pred_final = pd.concat(subcat_predictions + [fallback_rows])
        df_out = pd.concat([df_sub_pred_final, df_sub_mapped], axis=0).sort_index()

        df_out['source_file'] = f
        all_results.append(df_out)

    log(" Combining all results into one DataFrame...")
    final_df = pd.concat(all_results, axis=0, ignore_index=True)

    log(" Removing duplicates by CMPNT_MATL_NUM...")
    final_df['priority'] = final_df['prediction_flag'].map({
    'Mapped_PreExtracted': 2,
    'Mapped': 2,
    'High Confidence': 1,
    'Low Confidence': 0}).fillna(0)
    # Sort to put mapped rows first
    final_df = final_df.sort_values(by=['CMPNT_MATL_NUM', 'priority'], ascending=[True, False])
    # Drop duplicates, keeping highest priority (mapped rows)
    final_df = final_df.drop_duplicates(subset='CMPNT_MATL_NUM', keep='first')

    #final_df = final_df.drop_duplicates(subset='CMPNT_MATL_NUM')

    
    # Save separate samples for mapped and predicted
    sample_dir = os.path.join("outputs", "samples_by_source")
    os.makedirs(sample_dir, exist_ok=True)

    # Mapped rows
    mapped_rows = final_df[final_df['prediction_flag'].str.contains("Mapped")]
    mapped_rows.head(100).to_csv(os.path.join(sample_dir, "sample_mapped_rows.csv"), index=False)

    # Predicted rows (inferred by model)
    predicted_rows = final_df[final_df['prediction_flag'].isin(["High Confidence", "Low Confidence"])]
    predicted_rows.head(100).to_csv(os.path.join(sample_dir, "sample_predicted_rows.csv"), index=False)
    final_df.to_parquet("outputs/final_prediction_combined.parquet", index=False)
    log(" Saved combined output as final_prediction_combined.parquet and sample CSV")

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--input_path", type=str, required=True)
    parser.add_argument("--additional_mapped_dir", type=str, required=True)
    parser.add_argument("--key_output_dir", type=str, required=True)
    args = parser.parse_args()

    main(args.input_path, args.additional_mapped_dir)

    log(" Mapping predictions back to original key files...")
    key_files = [f for f in os.listdir(args.key_output_dir) if f.endswith(".parquet")]
    mapped_keys_dir = os.path.join("outputs", "mapped_keys")
    os.makedirs(mapped_keys_dir, exist_ok=True)

    
    final_df = pd.read_parquet("outputs/final_prediction_combined.parquet")
    # Rename columns for final output
    final_df = final_df.rename(columns={
        "Final_Prediction": "AI_FINAL_CATEGORY",
        "Final Subcategory": "AI_FINAL_SUBCATEGORY",
        "Score": "AI_FINAL_CATEGORY_CONFIDENCE",
        "Subcategory_Score": "AI_FINAL_SUBCATEGORY_CONFIDENCE",
        "inferred_category_model": "AI_MATCHING_REASON_FINAL_CATEGORY",
        "Subcategory_Model": "AI_MATCHING_REASON_FINAL_SUBCATEGORY"
    })

    

    for key_file in key_files:
        key_path = os.path.join(args.key_output_dir, key_file)
        try:
            key_df = pd.read_parquet(key_path)
            merged_df = key_df.merge(
                final_df[[
                    "CMPNT_MATL_NUM",
                    "AI_FINAL_CATEGORY",
                    "AI_FINAL_SUBCATEGORY",
                    "AI_FINAL_CATEGORY_CONFIDENCE",
                    "AI_FINAL_SUBCATEGORY_CONFIDENCE",
                    "AI_MATCHING_REASON_FINAL_CATEGORY",
                    "AI_MATCHING_REASON_FINAL_SUBCATEGORY"
                ]],
                how="left", on="CMPNT_MATL_NUM"
            )
            out_path = os.path.join(mapped_keys_dir, key_file)
            merged_df.to_parquet(out_path, index=False)
            log(f"✅ Saved mapped key file: {out_path}")
        except Exception as e:
            log(f"❌ Failed to process key file {key_file}: {e}")

    # ✅ Upload to ADLS2 (bom-xref) in hbom_category_prediction_DDMMYYYY format


    curr_time = time.strftime("%d%m%Y", time.localtime())
    output_folder_name = f"hbom_category_prediction_{curr_time}"
    upload_dir = os.path.join("outputs", "upload_dir")
    os.makedirs(upload_dir, exist_ok=True)

    for key_file in key_files:
        try:
            source_path = os.path.join(mapped_keys_dir, key_file)
            target_path = os.path.join(upload_dir, key_file)
            if os.path.exists(source_path):
                shutil.copy2(source_path, target_path)
        except Exception as e:
            log(f"❌ Failed to copy {key_file} to upload_dir: {e}")

    try:
        run = Run.get_context()
        if run.identity.startswith("OfflineRun"):
            ws = Workspace.from_config()
        else:
            ws = run.experiment.workspace

        ds = Datastore.get(ws, "bom-xref")

        Dataset.File.upload_directory(
            src_dir=upload_dir,
            target=ds.path(output_folder_name),
            overwrite=True
        )

        log(f"✅ Uploaded merged files to ADLS2 path: bom-xref/{output_folder_name}/")
    except Exception as e:
        log(f"❌ ADLS2 upload failed: {e}")

ROW_NM	RGN_NM	MATL_NUM	MATL_TYPE_CD	MATL_SHRT_DESC	MATL_UOM_CD	BOM_USG_CD	BOM_CAT_CD	BOM_NUM	ALT_BOM_NUM	PLNT_CD	BOM_UOM_CD	PREV_LVL_MATL_NUM	PREV_LVL_BOM_NUM	PREV_LVL_ALT_BOM_NUM	PREV_LVL_BOM_UOM_CD	PREV_LVL_PLNT_CD	SUB_MATL_NUM	SUB_BOM_NUM	SUB_ALT_BOM_NUM	SUB_BOM_UOM_CD	SUB_PLNT_CD	BOM_LVL_NUM	BOM_LVL_DTLS_NUM	CMPNT_MATL_NUM	CMPNT_MATL_DESC	CMPNT_MATL_TYPE_CD	CMPNT_UOM_CD	BOM_BASE_VAL	FG_CMPNT_VAL	CMPNT_RQST_VAL	CMPNT_USG_FACT_VAL	FG_CMPNT_USG_FACT_VAL	CNV_FG_CMPNT_VAL	CNV_CMPNT_RQST_VAL	CNV_CMPNT_USG_FACT_VAL	CNV_FG_CMPNT_USG_FACT_VAL	CNV_BASE_UOM_CD	CMPNT_SCRAP_VAL	OPR_CMPNT_SCRAP_VAL	FIN_GOOD_COMPONET_SCRAP_PCT	FIN_GOOD_COMPONET_SCRAP_QTY	FX_QTY_IND	BOM_ITM_BULK_IND	BOM_ITM_CHG_NUM	BOM_ITM_NUM	BOM_FLOW_CD	BOM_FLOW_CD_FLTR	BOM_DEL_IND	TRU_MATL_NUM	MATL_GRP_CD	MATL_CAT_CD_DESC	RAW_MATL_TITLE_NM	MATL_NET_CNTNT_DESC	MATL_NET_CNTNT_UOM_CD	FNSHD_GOODS_SPEC_CD	FNSHD_GOODS_SPEC_NM	FNSHD_GOODS_TYPE_CD	DP_CLSN_CD	CMPNT_BOM_CAT_CD	CMPNT_BOM_NUM	CMPNT_ALT_BOM_NUM	CMPNT_RM_SPEC_CD	CMPNT_PC_SPEC_CD	CMPNT_DC_SPEC_CD	CMPNT_CAT_CD_DESC	SUP_NUM	SUP_NM	IM_EM_CD	FD_SPEC_CD	CNFDN_CD	VERIF_STS_CD	MTCH_RSN_DESC	COUNT_SCORE	WEIGHT	VERIF_FLAG	ITM_PRVSN_IND	TEMPL_TYPE_CD	TEMPL_TYPE_CD_AI_SUGGESTED	DAI_BTCH_ID	LOGL_KEY_COMB_COL_NM	LOGL_KEY_COMB_COL_VAL	SRC_SYS_CD	Direct Mapping	Final Category	Final Subcategory	matching_reason	confidence_score	Final Category Filled	Final Subcategory Filled	needs_model	Score	Predicted	Final_Prediction	Subcategory_Score	Subcategory_Model	Predicted_Subcategory	prediction_flag	inferred_category_model	source_file	CMPNT_MATL_DESC_CLEAN	CMPNT_MATL_DESC_LEN	UNIT_GROUP	CMPNT_MATL_TYPE_CATEGORY	priority
7381456	LATAM	000000000000090067	HALB	ESPARAD.IMP.J'S* 12MMX4,5M	ROL	1	M	00002080	01	BR12	ROL	000000000000090067	00002080	01	ROL	BR12	000000000000090067	00002080	01	ROL	BR12	1	1.2	000000000000011359	CAPA IMPR. P/ESP. IMP.12X4,5	HALB	TH	1000	1	1	0.001	0.001	1	1	0.001	0.001	TH	0	0.2				N		0020	000000000000090067 (01) > 000000000000011359	000000000000090067 (01)	N		02	Semi Acabados														Embalagens RÃ­gidas														1	ROW_NM|^SRC_SYS_CD|^MATL_NUM|^PLNT_CD|^CMPNT_MATL_NUM|^BOM_LVL_DTLS_NUM|^TRU_MATL_NUM|^CMPNT_RM_SPEC_CD|^CMPNT_PC_SPEC_CD|^CMPNT_DC_SPEC_CD|^RAW_MATL_TITLE_NM		CLA	Embalagens RÃ­gidas	PKG	Other	direct_mapping_category	1	TRUE	FALSE	TRUE	0.5418388128767153	PKG	Other	0.9	default_fallback		Low Confidence	lightgbm_Bert_RPM_Category_model	part-00000-0042fc95-a813-4a78-a5ea-9d565974a2b5-c000.snappy.parquet	pa impr p esp imp12x45	28	Unclassified	SEMI_FINISHED	0
7371287	LATAM	000000000000091118	HALB	ESPARADRAPO P.SENS.J*12MMX4,5M	ROL	1	M	00002584	01	BR12	ROL	000000000000091118	00002584	01	ROL	BR12	000000000000091118	00002584	01	ROL	BR12	1	1.2	000000000000011361	CAPA IMP.P/ESP.P.SENS.12X4,5	HALB	TH	1000	1	1	0.001	0.001	1	1	0.001	0.001	TH	0	0.2				N		0020	000000000000091118 (01) > 000000000000011361	000000000000091118 (01)	N		02	Semi Acabados														Embalagens RÃ­gidas														1	ROW_NM|^SRC_SYS_CD|^MATL_NUM|^PLNT_CD|^CMPNT_MATL_NUM|^BOM_LVL_DTLS_NUM|^TRU_MATL_NUM|^CMPNT_RM_SPEC_CD|^CMPNT_PC_SPEC_CD|^CMPNT_DC_SPEC_CD|^RAW_MATL_TITLE_NM		CLA	Embalagens RÃ­gidas	PKG	Other	direct_mapping_category	1	TRUE	FALSE	TRUE	0.48855354752824415	CHM	Other	0.9	default_fallback		Low Confidence	lightgbm_Bert_RPM_Category_model	part-00000-0042fc95-a813-4a78-a5ea-9d565974a2b5-c000.snappy.parquet	pa impp esppsensitive12x45	28	Unclassified	SEMI_FINISHED	0
7319668	LATAM	000000000000093946	HALB	ESP.CIRURGICO 12X45  163007	ROL	1	M	00002778	01	BR12	ROL	000000000000093946	00002778	01	ROL	BR12	000000000000093946	00002778	01	ROL	BR12	1	1.3	000000000000011364	CAPA IMP.P/ESP.CIRURG.12X4,5	HALB	TH	1000	1	1	0.001	0.001	1	1	0.001	0.001	TH	0	0.2				N		0030	000000000000093946 (01) > 000000000000011364	000000000000093946 (01)	N		02	Semi Acabados														Embalagens RÃ­gidas	0000003337	PLASTICOS RO NA INDE COM LTDA												1	ROW_NM|^SRC_SYS_CD|^MATL_NUM|^PLNT_CD|^CMPNT_MATL_NUM|^BOM_LVL_DTLS_NUM|^TRU_MATL_NUM|^CMPNT_RM_SPEC_CD|^CMPNT_PC_SPEC_CD|^CMPNT_DC_SPEC_CD|^RAW_MATL_TITLE_NM		CLA	Embalagens RÃ­gidas	PKG	Other	direct_mapping_category	1	TRUE	FALSE	TRUE	0.4664620633893125	PKG	Other	0.9	default_fallback		Low Confidence	lightgbm_Bert_RPM_Category_model	part-00000-0042fc95-a813-4a78-a5ea-9d565974a2b5-c000.snappy.parquet	pa impp espcirurg12x45	28	Unclassified	SEMI_FINISHED	0
5465197	NA	000000000243010100	FERT	SF UT OVN WINGS CAN 40	EA	1	M	00083003	02	CA01	EA	000000000243010100	00083003	02	EA	CA01	000000000030010792	00080876	01	TH	CA01	2	1.1.4	000000000000020849	TISSU 58MM LIGHBLUEPRINT 228MM	ROH	M	10	38928	2433	243.3	9.732	38928	2433	243.3	9.732	M	4.9	0				N	MTL20110517	0020	000000000243010100 (02) > 000000000030010792 (01) > 000000000000020849	000000000243010100 (02) > 000000000030010792 (01)	N		FG0007	International		40	1N				C							Paper/Tissues														1	ROW_NM|^SRC_SYS_CD|^MATL_NUM|^PLNT_CD|^CMPNT_MATL_NUM|^BOM_LVL_DTLS_NUM|^TRU_MATL_NUM|^CMPNT_RM_SPEC_CD|^CMPNT_PC_SPEC_CD|^CMPNT_DC_SPEC_CD|^RAW_MATL_TITLE_NM		US1	Paper/Tissues	PKG	Other	direct_mapping_category	1	TRUE	FALSE	TRUE	0.5095484603687845	CHM	Other	0.9	default_fallback		Low Confidence	lightgbm_Bert_RPM_Category_model	part-00000-0042fc95-a813-4a78-a5ea-9d565974a2b5-c000.snappy.parquet	tissu 58mm lighblueprint 228mm	30	Dimensional	RAW_MATERIAL	0

