import pandas as pd
import os

# === CONFIGURATION ===
csv_path = './data/combined.csv'
parquet_path = './data/combined.parquet'
target_map_path = './data/cleaned_parts/target_map.csv'
output_parquet_path = './data/combined_with_target.parquet'

# === STEP 1: Convert huge CSV to single Parquet ===
if not os.path.exists(parquet_path):
    print("ğŸ” Converting CSV to Parquet...")
    chunk_list = []
    for chunk in pd.read_csv(csv_path, chunksize=1_000_000):
        chunk = chunk.drop_duplicates()
        chunk_list.append(chunk)
    combined_df = pd.concat(chunk_list, ignore_index=True)
    combined_df.to_parquet(parquet_path, index=False)
    del chunk_list, combined_df
    print("âœ… CSV converted to Parquet:", parquet_path)

# === STEP 2: Load target_map ===
print("ğŸ“¥ Loading target map...")
target_map = pd.read_csv(target_map_path, usecols=['CMPNT_CAT_CD_DESC', 'Final Category'])
target_map = target_map.drop_duplicates()
target_map['CMPNT_CAT_CD_DESC'] = target_map['CMPNT_CAT_CD_DESC'].astype('category')

# === STEP 3: Merge in chunks and write to new Parquet ===
print("ğŸ” Merging with target_map in chunks...")
parquet_reader = pd.read_parquet(parquet_path, engine='pyarrow', chunksize=1_000_000)
first = True

for chunk in parquet_reader:
    chunk = chunk.drop_duplicates()
    chunk['CMPNT_CAT_CD_DESC'] = chunk['CMPNT_CAT_CD_DESC'].astype('category')
    merged = chunk.merge(target_map, how='left', on='CMPNT_CAT_CD_DESC')

    # Save the first chunk with headers, then append others
    merged.to_parquet(output_parquet_path, index=False, engine='pyarrow', append=not first)
    first = False

print("âœ… Merging complete. Output saved to:", output_parquet_path)
