pip install pydub
from pydub import AudioSegment

from pydub import AudioSegment  # Ensure this is imported at the top

def translate_audio(audio_path, translated_wav, from_lang, to_lang):
    voice_map = {
        "fr": "fr-FR-DeniseNeural",
        "de": "de-DE-KatjaNeural",
        "es": "es-ES-ElviraNeural",
        "it": "it-IT-ElsaNeural",
        "pt": "pt-BR-FranciscaNeural",
        "zh-Hans": "zh-CN-XiaoxiaoNeural",
        "ja": "ja-JP-NanamiNeural",
        "ko": "ko-KR-SunHiNeural",
        "ru": "ru-RU-DariyaNeural",
        "hi": "hi-IN-SwaraNeural",
        "ar": "ar-EG-SalmaNeural",
        "tr": "tr-TR-EmelNeural",
        "nl": "nl-NL-ColetteNeural",
        "pl": "pl-PL-AgnieszkaNeural",
        "th": "th-TH-PremNeural",
        "sv": "sv-SE-SofieNeural",
        "cs": "cs-CZ-VlastaNeural",
        "hu": "hu-HU-NoemiNeural"
    }

    translation_config = speechsdk.translation.SpeechTranslationConfig(
        endpoint=CUSTOM_ENDPOINT, subscription=SPEECH_KEY
    )
    translation_config.speech_recognition_language = from_lang
    translation_config.add_target_language(to_lang)
    translation_config.voice_name = voice_map.get(to_lang, "fr-FR-DeniseNeural")

    audio_config = speechsdk.audio.AudioConfig(filename=audio_path)
    recognizer = speechsdk.translation.TranslationRecognizer(
        translation_config=translation_config, audio_config=audio_config
    )

    result = recognizer.recognize_once()
    if result.reason != speechsdk.ResultReason.TranslatedSpeech:
        raise Exception("Translation failed: " + str(result.reason))

    translated_text = result.translations[to_lang]

    speech_config = speechsdk.SpeechConfig(subscription=SPEECH_KEY, endpoint=CUSTOM_ENDPOINT)
    speech_config.speech_synthesis_voice_name = translation_config.voice_name
    audio_out = speechsdk.audio.AudioOutputConfig(filename=translated_wav)

    synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=audio_out)
    synthesizer.speak_text_async(translated_text).get()

    # Padding the translated audio to match original audio length
    original_audio = AudioSegment.from_wav(audio_path)
    translated_audio = AudioSegment.from_wav(translated_wav)

    if len(translated_audio) < len(original_audio):
        silence = AudioSegment.silent(duration=len(original_audio) - len(translated_audio))
        padded_audio = translated_audio + silence
        padded_audio.export(translated_wav, format="wav")

    return translated_text


def stitch_audio_to_video(original_video, translated_audio, output_video):
    command = [
        FFMPEG_PATH, "-y", "-i", original_video,
        "-i", translated_audio, "-c:v", "copy",
        "-map", "0:v:0", "-map", "1:a:0",
        output_video  # no "-shortest" here
    ]
    subprocess.run(command, check=True)
