import os
import uuid
import shutil
import subprocess
from pydub import AudioSegment, silence
import gradio as gr
import azure.cognitiveservices.speech as speechsdk

# Azure Speech settings
SPEECH_KEY = ""
CUSTOM_ENDPOINT = "https://cog-speech-dto-epil-dev.cognitiveservices.azure.com/"

# Path to ffmpeg.exe
FFMPEG_PATH = r"C:/Users/AChava05/Downloads/ffmpeg-2025-06-28-git-cfd1f81e7d-essentials_build/ffmpeg-2025-06-28-git-cfd1f81e7d-essentials_build/bin/ffmpeg.exe"

# Supported languages
SOURCE_LANGUAGES = {
    "English (US)": "en-US",
    "French (France)": "fr-FR",
    "German": "de-DE",
    "Italian": "it-IT",
    "Spanish": "es-ES",
    "Portuguese (Brazil)": "pt-BR",
    "Chinese (Mandarin)": "zh-CN",
    "Japanese": "ja-JP",
    "Korean": "ko-KR",
    "Russian": "ru-RU",
    "Hindi": "hi-IN",
    "Arabic": "ar-EG",
    "Turkish": "tr-TR",
    "Dutch": "nl-NL",
    "Polish": "pl-PL",
    "Thai": "th-TH",
    "Swedish": "sv-SE",
    "Czech": "cs-CZ",
    "Hungarian": "hu-HU"
}

TARGET_LANGUAGES = {
    "French": "fr",
    "German": "de",
    "Spanish": "es",
    "Italian": "it",
    "Portuguese": "pt",
    "Chinese": "zh-Hans",
    "Japanese": "ja",
    "Korean": "ko",
    "Russian": "ru",
    "Hindi": "hi",
    "Arabic": "ar",
    "Turkish": "tr",
    "Dutch": "nl",
    "Polish": "pl",
    "Thai": "th",
    "Swedish": "sv",
    "Czech": "cs",
    "Hungarian": "hu"
}

def extract_audio(video_path, audio_path):
    command = [
        FFMPEG_PATH, "-y", "-i", video_path,
        "-vn", "-acodec", "pcm_s16le", "-ar", "16000", "-ac", "1", audio_path
    ]
    subprocess.run(command, check=True)

def translate_audio_segmented(audio_path, translated_wav, from_lang, to_lang):
    audio = AudioSegment.from_wav(audio_path)
    segments = silence.split_on_silence(audio, min_silence_len=500, silence_thresh=audio.dBFS - 16, keep_silence=250)

    print(f"Found {len(segments)} segments.")
    translated_audio_segments = []

    translation_config = speechsdk.translation.SpeechTranslationConfig(
        subscription=SPEECH_KEY,
        endpoint=CUSTOM_ENDPOINT,
        speech_recognition_language=from_lang
    )
    translation_config.add_target_language(to_lang)

    voice_map = {
        "fr": "fr-FR-DeniseNeural",
        "de": "de-DE-KatjaNeural",
        "es": "es-ES-ElviraNeural",
        "it": "it-IT-ElsaNeural",
        "pt": "pt-BR-FranciscaNeural",
        "zh-Hans": "zh-CN-XiaoxiaoNeural",
        "ja": "ja-JP-NanamiNeural",
        "ko": "ko-KR-SunHiNeural",
        "ru": "ru-RU-DariyaNeural",
        "hi": "hi-IN-SwaraNeural",
        "ar": "ar-EG-SalmaNeural",
        "tr": "tr-TR-EmelNeural",
        "nl": "nl-NL-ColetteNeural",
        "pl": "pl-PL-AgnieszkaNeural",
        "th": "th-TH-PremNeural",
        "sv": "sv-SE-SofieNeural",
        "cs": "cs-CZ-VlastaNeural",
        "hu": "hu-HU-NoemiNeural"
    }
    translation_config.voice_name = voice_map.get(to_lang, "fr-FR-DeniseNeural")
    speech_config = speechsdk.SpeechConfig(subscription=SPEECH_KEY, endpoint=CUSTOM_ENDPOINT)
    speech_config.speech_synthesis_voice_name = translation_config.voice_name

    for i, segment in enumerate(segments):
        temp_seg_path = f"segment_{i}.wav"
        segment.export(temp_seg_path, format="wav")

        audio_input = speechsdk.audio.AudioConfig(filename=temp_seg_path)
        recognizer = speechsdk.translation.TranslationRecognizer(
            translation_config=translation_config,
            audio_config=audio_input
        )
        result = recognizer.recognize_once()

        if result.reason == speechsdk.ResultReason.TranslatedSpeech:
            translated_text = result.translations[to_lang]
            print(f"[Segment {i}] Translated: {translated_text}")

            temp_out_path = f"tts_{i}.wav"
            audio_output = speechsdk.audio.AudioOutputConfig(filename=temp_out_path)
            synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=audio_output)
            synthesizer.speak_text_async(translated_text).get()

            tts_segment = AudioSegment.from_file(temp_out_path, format="wav")
            translated_audio_segments.append(tts_segment)

            import time
            time.sleep(0.1)
            try:
                os.remove(temp_out_path)
            except PermissionError:
                print(f"Warning: Could not delete {temp_out_path}. File still in use.")
        else:
            translated_audio_segments.append(AudioSegment.silent(duration=len(segment)))

        os.remove(temp_seg_path)

    final_audio = sum(translated_audio_segments)
    final_audio.export(translated_wav, format="wav")

    return "Translation complete."

def stitch_audio_to_video(original_video, translated_audio, output_video):
    command = [
        FFMPEG_PATH, "-y", "-i", original_video,
        "-i", translated_audio, "-c:v", "copy",
        "-map", "0:v:0", "-map", "1:a:0",
        output_video
    ]
    subprocess.run(command, check=True)

def process_video(video_file_obj, from_lang_label, to_lang_label):
    from_lang = SOURCE_LANGUAGES[from_lang_label]
    to_lang = TARGET_LANGUAGES[to_lang_label]

    uid = str(uuid.uuid4())
    video_path = f"video_{uid}.mp4"
    audio_path = f"audio_{uid}.wav"
    translated_wav = f"translated_{uid}.wav"
    output_path = f"translated_video_{uid}.mp4"

    shutil.copy(video_file_obj, video_path)

    extract_audio(video_path, audio_path)
    translate_audio_segmented(audio_path, translated_wav, from_lang, to_lang)
    stitch_audio_to_video(video_path, translated_wav, output_path)

    return output_path

gui = gr.Interface(
    fn=process_video,
    inputs=[
        gr.File(label="Upload Video", file_types=[".mp4"]),
        gr.Dropdown(choices=list(SOURCE_LANGUAGES.keys()), label="Source Language", value="English (US)"),
        gr.Dropdown(choices=list(TARGET_LANGUAGES.keys()), label="Target Language", value="French")
    ],
    outputs=gr.Video(label="Translated Video"),
    title="ðŸŽ¬ Video Translator with Azure AI",
    description="Upload a video, select source and target languages, and get back a translated video with aligned audio."
)

gui.launch()
